{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d5f719",
   "metadata": {},
   "source": [
    "build your ops.yaml from data-juicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "031b9bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 14:00:08.127 | INFO     | data_juicer.ops:timing_context:12 - Importing operator modules took 10.40 seconds\n"
     ]
    }
   ],
   "source": [
    "from data_juicer.tools.op_search import OPSearcher\n",
    "\n",
    "op_records = OPSearcher().search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c92d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import inspect\n",
    "from annotated_types import Gt, Lt\n",
    "\n",
    "def build_arg_state_from_signature(sig: inspect.Signature):\n",
    "\n",
    "    arg_state = {}\n",
    "    for name, param in sig.parameters.items():\n",
    "        if name == 'self' or name == 'args' or name == 'kwargs':\n",
    "            continue\n",
    "        param_dict = {}\n",
    "        ann = param.annotation\n",
    "\n",
    "        if ann is inspect._empty:\n",
    "            param_dict['type'] = 'str'\n",
    "        elif ann is str:\n",
    "            param_dict['type'] = 'str'\n",
    "        elif ann is bool:\n",
    "            param_dict['type'] = 'bool'\n",
    "            param_dict['default'] = True\n",
    "        elif ann is int:\n",
    "            param_dict['type'] = 'int'\n",
    "        elif ann is float:\n",
    "            param_dict['type'] = 'float'\n",
    "        elif hasattr(ann, '__origin__') and ann.__origin__ is list:\n",
    "            if hasattr(ann, '__args__') and ann.__args__[0] is str:\n",
    "                param_dict['type'] = 'list_str'\n",
    "            else:\n",
    "                # param_dict['type'] = 'list'\n",
    "                raise\n",
    "        elif hasattr(ann, '__origin__') and ann.__origin__ is int:\n",
    "            param_dict['type'] = 'int'\n",
    "            for meta in ann.__metadata__:\n",
    "                if isinstance(meta, Gt):\n",
    "                    param_dict['min'] = meta.gt\n",
    "                if isinstance(meta, Lt):\n",
    "                    param_dict['max'] = meta.lt\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported type: {ann}\")\n",
    "\n",
    "        if param.default is inspect._empty or param.default is None:\n",
    "            param_dict['default'] = \"\"\n",
    "        else:\n",
    "            if type(param.default) != ann and not isinstance(param.default, list) and param.default != sys.maxsize:\n",
    "                re_pattern = r\"<class '(.*)'>\"\n",
    "                str_type = re.search(re_pattern, str(type(param.default))).group(1)\n",
    "                param_dict['type'] = str_type\n",
    "            max_value = 9007199254740991.0\n",
    "            min_value = -9007199254740991.0\n",
    "            if isinstance(param.default, (int, float)):\n",
    "                if param.default > max_value:\n",
    "                    param_dict['default'] = max_value if isinstance(param.default, float) else int(max_value)\n",
    "                elif param.default < min_value:\n",
    "                    param_dict['default'] = min_value if isinstance(param.default, float) else int(min_value)\n",
    "                else:\n",
    "                    param_dict['default'] = param.default\n",
    "            else:\n",
    "                param_dict['default'] = param.default\n",
    "\n",
    "        arg_state[name] = param_dict\n",
    "\n",
    "    return arg_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0bcdd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_ops = {}\n",
    "for op_record in op_records:\n",
    "    op_sig = op_record['signature']\n",
    "    try:\n",
    "        arg_state = build_arg_state_from_signature(op_sig)\n",
    "    except Exception:\n",
    "        continue\n",
    "    if op_record[\"name\"] in [\"general_field_filter\", \"download_file_mapper\", \"sdxl_prompt2prompt_mapper\", \"sentence_augmentation_mapper\", \"naive_grouper\", \"naive_reverse_grouper\", \"tags_specified_field_selector\"]:\n",
    "        continue\n",
    "    custom_ops[op_record[\"name\"]] = {\"args\":arg_state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342f5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"./configs/all_ops.yaml\", \"w\") as f:\n",
    "    yaml.dump(custom_ops, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd74c4d5",
   "metadata": {},
   "source": [
    "Test operator pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa20a90be87a54a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T07:01:23.951063Z",
     "start_time": "2025-06-18T07:01:23.404565Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 14:00:23.398 | INFO     | operator_pool:__init__:225 - Operator: __init__: alphanumeric_filter args: {'max_ratio': {'default': 9007199254740991, 'type': 'float'}, 'min_ratio': {'default': 0.25, 'type': 'float'}, 'tokenization': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.399 | INFO     | operator_pool:__init__:225 - Operator: __init__: audio_add_gaussian_noise_mapper args: {'max_amplitude': {'default': 0.015, 'type': 'float'}, 'min_amplitude': {'default': 0.001, 'type': 'float'}, 'p': {'default': 0.5, 'type': 'float'}}\n",
      "2025-07-10 14:00:23.400 | INFO     | operator_pool:__init__:225 - Operator: __init__: audio_duration_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'max_duration': {'default': 9007199254740991, 'type': 'int'}, 'min_duration': {'default': 0, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.400 | INFO     | operator_pool:__init__:225 - Operator: __init__: audio_nmf_snr_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'max_snr': {'default': 9007199254740991, 'type': 'float'}, 'min_snr': {'default': 0, 'type': 'int'}, 'nmf_iter_num': {'default': 500, 'min': 0, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.400 | INFO     | operator_pool:__init__:225 - Operator: __init__: audio_size_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'max_size': {'default': '1TB', 'type': 'str'}, 'min_size': {'default': '0', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.401 | INFO     | operator_pool:__init__:225 - Operator: __init__: average_line_length_filter args: {'max_len': {'default': 9007199254740991, 'type': 'int'}, 'min_len': {'default': 10, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.401 | INFO     | operator_pool:__init__:225 - Operator: __init__: character_repetition_filter args: {'max_ratio': {'default': 0.5, 'type': 'float'}, 'min_ratio': {'default': 0.0, 'type': 'float'}, 'rep_len': {'default': 10, 'min': 0, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.401 | INFO     | operator_pool:__init__:225 - Operator: __init__: chinese_convert_mapper args: {'mode': {'default': 's2t', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.402 | INFO     | operator_pool:__init__:225 - Operator: __init__: clean_copyright_mapper args: {}\n",
      "2025-07-10 14:00:23.402 | INFO     | operator_pool:__init__:225 - Operator: __init__: clean_html_mapper args: {}\n",
      "2025-07-10 14:00:23.403 | INFO     | operator_pool:__init__:225 - Operator: __init__: document_deduplicator args: {'ignore_non_character': {'default': False, 'type': 'bool'}, 'lowercase': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.403 | INFO     | operator_pool:__init__:225 - Operator: __init__: expand_macro_mapper args: {}\n",
      "2025-07-10 14:00:23.404 | INFO     | operator_pool:__init__:225 - Operator: __init__: extract_tables_from_html_mapper args: {'include_header': {'default': True, 'type': 'bool'}, 'retain_html_tags': {'default': False, 'type': 'bool'}, 'tables_field_name': {'default': 'html_tables', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.404 | INFO     | operator_pool:__init__:225 - Operator: __init__: fix_unicode_mapper args: {'normalization': {'default': '', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.405 | INFO     | operator_pool:__init__:225 - Operator: __init__: human_preference_annotation_mapper args: {'answer1_key': {'default': 'answer1', 'type': 'str'}, 'answer2_key': {'default': 'answer2', 'type': 'str'}, 'chosen_key': {'default': 'chosen', 'type': 'str'}, 'label_config_file': {'default': '', 'type': 'str'}, 'prompt_key': {'default': 'prompt', 'type': 'str'}, 'rejected_key': {'default': 'rejected', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.405 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_aesthetics_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'hf_scorer_model': {'default': '', 'type': 'str'}, 'max_score': {'default': 1.0, 'type': 'float'}, 'min_score': {'default': 0.5, 'type': 'float'}, 'trust_remote_code': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.406 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_aspect_ratio_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'max_ratio': {'default': 3.0, 'type': 'float'}, 'min_ratio': {'default': 0.333, 'type': 'float'}}\n",
      "2025-07-10 14:00:23.407 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_blur_mapper args: {'blur_type': {'default': 'gaussian', 'type': 'str'}, 'p': {'default': 0.2, 'type': 'float'}, 'radius': {'default': 2, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.408 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_deduplicator args: {'consider_text': {'default': False, 'type': 'bool'}, 'method': {'default': 'phash', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.408 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_face_count_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'cv_classifier': {'default': '', 'type': 'str'}, 'max_face_count': {'default': 1, 'type': 'int'}, 'min_face_count': {'default': 1, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.409 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_face_ratio_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'cv_classifier': {'default': '', 'type': 'str'}, 'max_ratio': {'default': 0.4, 'type': 'float'}, 'min_ratio': {'default': 0.0, 'type': 'float'}}\n",
      "2025-07-10 14:00:23.409 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_nsfw_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'hf_nsfw_model': {'default': 'Falconsai/nsfw_image_detection', 'type': 'str'}, 'max_score': {'default': 0.5, 'type': 'float'}, 'trust_remote_code': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.410 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_segment_mapper args: {'conf': {'default': 0.05, 'type': 'float'}, 'imgsz': {'default': 1024, 'type': 'int'}, 'iou': {'default': 0.5, 'type': 'float'}, 'model_path': {'default': 'FastSAM-x.pt', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.410 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_shape_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'max_height': {'default': 9007199254740991, 'type': 'int'}, 'max_width': {'default': 9007199254740991, 'type': 'int'}, 'min_height': {'default': 1, 'type': 'int'}, 'min_width': {'default': 1, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.411 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_size_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'max_size': {'default': '1TB', 'type': 'str'}, 'min_size': {'default': '0', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.412 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_tagging_mapper args: {'tag_field_name': {'default': 'image_tags', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.412 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_text_matching_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'hf_blip': {'default': 'Salesforce/blip-itm-base-coco', 'type': 'str'}, 'horizontal_flip': {'default': False, 'type': 'bool'}, 'max_score': {'default': 1.0, 'type': 'float'}, 'min_score': {'default': 0.003, 'type': 'float'}, 'reduce_mode': {'default': 'avg', 'type': 'str'}, 'trust_remote_code': {'default': False, 'type': 'bool'}, 'vertical_flip': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.413 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_text_similarity_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'hf_clip': {'default': 'openai/clip-vit-base-patch32', 'type': 'str'}, 'horizontal_flip': {'default': False, 'type': 'bool'}, 'max_score': {'default': 1.0, 'type': 'float'}, 'min_score': {'default': 0.1, 'type': 'float'}, 'reduce_mode': {'default': 'avg', 'type': 'str'}, 'trust_remote_code': {'default': False, 'type': 'bool'}, 'vertical_flip': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.413 | INFO     | operator_pool:__init__:225 - Operator: __init__: image_watermark_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'hf_watermark_model': {'default': 'amrul-hzz/watermark_detector', 'type': 'str'}, 'prob_threshold': {'default': 0.8, 'type': 'float'}, 'trust_remote_code': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.413 | INFO     | operator_pool:__init__:225 - Operator: __init__: maximum_line_length_filter args: {'max_len': {'default': 9007199254740991, 'type': 'int'}, 'min_len': {'default': 10, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.414 | INFO     | operator_pool:__init__:225 - Operator: __init__: mllm_mapper args: {'hf_model': {'default': 'llava-hf/llava-v1.6-vicuna-7b-hf', 'type': 'str'}, 'max_new_tokens': {'default': 256, 'type': 'int'}, 'num_beams': {'default': 1, 'type': 'int'}, 'temperature': {'default': 0.2, 'type': 'float'}, 'top_p': {'default': '', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.415 | INFO     | operator_pool:__init__:225 - Operator: __init__: nlpaug_en_mapper args: {'aug_num': {'default': 1, 'min': 0, 'type': 'int'}, 'delete_random_char': {'default': False, 'type': 'bool'}, 'delete_random_word': {'default': False, 'type': 'bool'}, 'insert_random_char': {'default': False, 'type': 'bool'}, 'keep_original_sample': {'default': True, 'type': 'bool'}, 'keyboard_error_char': {'default': False, 'type': 'bool'}, 'ocr_error_char': {'default': False, 'type': 'bool'}, 'sequential': {'default': False, 'type': 'bool'}, 'spelling_error_word': {'default': False, 'type': 'bool'}, 'split_random_word': {'default': False, 'type': 'bool'}, 'swap_random_char': {'default': False, 'type': 'bool'}, 'swap_random_word': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.415 | INFO     | operator_pool:__init__:225 - Operator: __init__: nlpcda_zh_mapper args: {'aug_num': {'default': 1, 'min': 0, 'type': 'int'}, 'delete_random_char': {'default': False, 'type': 'bool'}, 'keep_original_sample': {'default': True, 'type': 'bool'}, 'replace_equivalent_num': {'default': False, 'type': 'bool'}, 'replace_homophone_char': {'default': False, 'type': 'bool'}, 'replace_similar_word': {'default': False, 'type': 'bool'}, 'sequential': {'default': False, 'type': 'bool'}, 'swap_random_char': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.416 | INFO     | operator_pool:__init__:225 - Operator: __init__: perplexity_filter args: {'lang': {'default': 'en', 'type': 'str'}, 'max_ppl': {'default': 1500, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.416 | INFO     | operator_pool:__init__:225 - Operator: __init__: phrase_grounding_recall_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'conf_thr': {'default': 0.0, 'type': 'float'}, 'hf_owlvit': {'default': 'google/owlvit-base-patch32', 'type': 'str'}, 'horizontal_flip': {'default': False, 'type': 'bool'}, 'iou_thr': {'default': 0.5, 'type': 'float'}, 'large_area_ratio_thr': {'default': 0.95, 'type': 'float'}, 'max_recall': {'default': 1.0, 'type': 'float'}, 'min_recall': {'default': 0.1, 'type': 'float'}, 'reduce_mode': {'default': 'avg', 'type': 'str'}, 'trust_remote_code': {'default': False, 'type': 'bool'}, 'vertical_flip': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.417 | INFO     | operator_pool:__init__:225 - Operator: __init__: punctuation_normalization_mapper args: {}\n",
      "2025-07-10 14:00:23.418 | INFO     | operator_pool:__init__:225 - Operator: __init__: python_file_mapper args: {'batched': {'default': False, 'type': 'bool'}, 'file_path': {'default': '', 'type': 'str'}, 'function_name': {'default': 'process_single', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.419 | INFO     | operator_pool:__init__:225 - Operator: __init__: python_lambda_mapper args: {'batched': {'default': False, 'type': 'bool'}, 'lambda_str': {'default': '', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.419 | INFO     | operator_pool:__init__:225 - Operator: __init__: ray_document_deduplicator args: {'backend': {'default': 'ray_actor', 'type': 'str'}, 'ignore_non_character': {'default': False, 'type': 'bool'}, 'lowercase': {'default': False, 'type': 'bool'}, 'redis_address': {'default': 'redis://localhost:6379', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.420 | INFO     | operator_pool:__init__:225 - Operator: __init__: ray_image_deduplicator args: {'backend': {'default': 'ray_actor', 'type': 'str'}, 'method': {'default': 'phash', 'type': 'str'}, 'redis_address': {'default': 'redis://localhost:6379', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.420 | INFO     | operator_pool:__init__:225 - Operator: __init__: ray_video_deduplicator args: {'backend': {'default': 'ray_actor', 'type': 'str'}, 'redis_address': {'default': 'redis://localhost:6379', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.421 | INFO     | operator_pool:__init__:225 - Operator: __init__: remove_bibliography_mapper args: {}\n",
      "2025-07-10 14:00:23.421 | INFO     | operator_pool:__init__:225 - Operator: __init__: remove_header_mapper args: {'drop_no_head': {'default': True, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.422 | INFO     | operator_pool:__init__:225 - Operator: __init__: remove_long_words_mapper args: {'max_len': {'default': 9007199254740991, 'type': 'int'}, 'min_len': {'default': 1, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.423 | INFO     | operator_pool:__init__:225 - Operator: __init__: remove_non_chinese_character_mapper args: {'keep_alphabet': {'default': True, 'type': 'bool'}, 'keep_number': {'default': True, 'type': 'bool'}, 'keep_punc': {'default': True, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.423 | INFO     | operator_pool:__init__:225 - Operator: __init__: remove_repeat_sentences_mapper args: {'ignore_special_character': {'default': True, 'type': 'bool'}, 'lowercase': {'default': False, 'type': 'bool'}, 'min_repeat_sentence_length': {'default': 2, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.424 | INFO     | operator_pool:__init__:225 - Operator: __init__: remove_table_text_mapper args: {'max_col': {'default': 20, 'type': 'int'}, 'min_col': {'default': 2, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.424 | INFO     | operator_pool:__init__:225 - Operator: __init__: sentence_split_mapper args: {'lang': {'default': 'en', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.425 | INFO     | operator_pool:__init__:225 - Operator: __init__: special_characters_filter args: {'max_ratio': {'default': 0.25, 'type': 'float'}, 'min_ratio': {'default': 0.0, 'type': 'float'}}\n",
      "2025-07-10 14:00:23.425 | INFO     | operator_pool:__init__:225 - Operator: __init__: specified_numeric_field_filter args: {'field_key': {'default': '', 'type': 'str'}, 'max_value': {'default': 9007199254740991, 'type': 'float'}, 'min_value': {'default': -9007199254740991, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.426 | INFO     | operator_pool:__init__:225 - Operator: __init__: text_action_filter args: {'lang': {'default': 'en', 'type': 'str'}, 'min_action_num': {'default': 1, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.426 | INFO     | operator_pool:__init__:225 - Operator: __init__: text_entity_dependency_filter args: {'any_or_all': {'default': 'all', 'type': 'str'}, 'lang': {'default': 'en', 'type': 'str'}, 'min_dependency_num': {'default': 1, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.427 | INFO     | operator_pool:__init__:225 - Operator: __init__: text_length_filter args: {'max_len': {'default': 9007199254740991, 'type': 'int'}, 'min_len': {'default': 10, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.427 | INFO     | operator_pool:__init__:225 - Operator: __init__: token_num_filter args: {'hf_tokenizer': {'default': 'EleutherAI/pythia-6.9b-deduped', 'type': 'str'}, 'max_num': {'default': 9007199254740991, 'type': 'int'}, 'min_num': {'default': 10, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.428 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_aesthetics_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'frame_num': {'default': 3, 'min': 0, 'type': 'int'}, 'frame_sampling_method': {'default': 'uniform', 'type': 'str'}, 'hf_scorer_model': {'default': '', 'type': 'str'}, 'max_score': {'default': 1.0, 'type': 'float'}, 'min_score': {'default': 0.4, 'type': 'float'}, 'reduce_mode': {'default': 'avg', 'type': 'str'}, 'trust_remote_code': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.428 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_aspect_ratio_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'max_ratio': {'default': '21/9', 'type': 'str'}, 'min_ratio': {'default': '9/21', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.429 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_captioning_from_audio_mapper args: {'keep_original_sample': {'default': True, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.429 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_deduplicator args: {'consider_text': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.429 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_duration_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'max_duration': {'default': 9007199254740991, 'type': 'float'}, 'min_duration': {'default': 0, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.432 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_extract_frames_mapper args: {'duration': {'default': 0, 'type': 'int'}, 'frame_dir': {'default': '', 'type': 'str'}, 'frame_key': {'default': 'video_frames', 'type': 'str'}, 'frame_num': {'default': 3, 'min': 0, 'type': 'int'}, 'frame_sampling_method': {'default': 'all_keyframes', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.432 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_face_blur_mapper args: {'blur_type': {'default': 'gaussian', 'type': 'str'}, 'cv_classifier': {'default': '', 'type': 'str'}, 'radius': {'default': 2, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.433 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_frames_text_similarity_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'frame_num': {'default': 3, 'min': 0, 'type': 'int'}, 'frame_sampling_method': {'default': 'all_keyframes', 'type': 'str'}, 'hf_clip': {'default': 'openai/clip-vit-base-patch32', 'type': 'str'}, 'horizontal_flip': {'default': False, 'type': 'bool'}, 'max_score': {'default': 1.0, 'type': 'float'}, 'min_score': {'default': 0.1, 'type': 'float'}, 'reduce_mode': {'default': 'avg', 'type': 'str'}, 'trust_remote_code': {'default': False, 'type': 'bool'}, 'vertical_flip': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.434 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_nsfw_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'frame_num': {'default': 3, 'min': 0, 'type': 'int'}, 'frame_sampling_method': {'default': 'all_keyframes', 'type': 'str'}, 'hf_nsfw_model': {'default': 'Falconsai/nsfw_image_detection', 'type': 'str'}, 'max_score': {'default': 0.5, 'type': 'float'}, 'reduce_mode': {'default': 'avg', 'type': 'str'}, 'trust_remote_code': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.434 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_resize_aspect_ratio_mapper args: {'max_ratio': {'default': '21/9', 'type': 'str'}, 'min_ratio': {'default': '9/21', 'type': 'str'}, 'strategy': {'default': 'increase', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.435 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_resize_resolution_mapper args: {'force_divisible_by': {'default': 2, 'min': 0, 'type': 'int'}, 'force_original_aspect_ratio': {'default': 'disable', 'type': 'str'}, 'max_height': {'default': 9007199254740991, 'type': 'int'}, 'max_width': {'default': 9007199254740991, 'type': 'int'}, 'min_height': {'default': 1, 'type': 'int'}, 'min_width': {'default': 1, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.435 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_resolution_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'max_height': {'default': 9007199254740991, 'type': 'int'}, 'max_width': {'default': 9007199254740991, 'type': 'int'}, 'min_height': {'default': 1, 'type': 'int'}, 'min_width': {'default': 1, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.436 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_split_by_duration_mapper args: {'keep_original_sample': {'default': True, 'type': 'bool'}, 'min_last_split_duration': {'default': 0, 'type': 'int'}, 'split_duration': {'default': 10, 'type': 'int'}}\n",
      "2025-07-10 14:00:23.436 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_split_by_key_frame_mapper args: {'keep_original_sample': {'default': True, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.438 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_tagging_from_audio_mapper args: {'hf_ast': {'default': 'MIT/ast-finetuned-audioset-10-10-0.4593', 'type': 'str'}, 'tag_field_name': {'default': 'video_audio_tags', 'type': 'str'}, 'trust_remote_code': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.439 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_tagging_from_frames_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'contain': {'default': 'any', 'type': 'str'}, 'frame_num': {'default': 3, 'min': 0, 'type': 'int'}, 'frame_sampling_method': {'default': 'all_keyframes', 'type': 'str'}, 'tag_field_name': {'default': 'video_frame_tags', 'type': 'str'}, 'tags': {'default': ['people'], 'type': 'list_str'}}\n",
      "2025-07-10 14:00:23.440 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_tagging_from_frames_mapper args: {'frame_num': {'default': 3, 'min': 0, 'type': 'int'}, 'frame_sampling_method': {'default': 'all_keyframes', 'type': 'str'}, 'tag_field_name': {'default': 'video_frame_tags', 'type': 'str'}}\n",
      "2025-07-10 14:00:23.440 | INFO     | operator_pool:__init__:225 - Operator: __init__: video_watermark_filter args: {'any_or_all': {'default': 'any', 'type': 'str'}, 'frame_num': {'default': 3, 'min': 0, 'type': 'int'}, 'frame_sampling_method': {'default': 'all_keyframes', 'type': 'str'}, 'hf_watermark_model': {'default': 'amrul-hzz/watermark_detector', 'type': 'str'}, 'prob_threshold': {'default': 0.8, 'type': 'float'}, 'reduce_mode': {'default': 'avg', 'type': 'str'}, 'trust_remote_code': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.441 | INFO     | operator_pool:__init__:225 - Operator: __init__: whitespace_normalization_mapper args: {}\n",
      "2025-07-10 14:00:23.442 | INFO     | operator_pool:__init__:225 - Operator: __init__: word_repetition_filter args: {'lang': {'default': 'en', 'type': 'str'}, 'max_ratio': {'default': 0.5, 'type': 'float'}, 'min_ratio': {'default': 0.0, 'type': 'float'}, 'rep_len': {'default': 10, 'min': 0, 'type': 'int'}, 'tokenization': {'default': False, 'type': 'bool'}}\n",
      "2025-07-10 14:00:23.442 | INFO     | operator_pool:__init__:225 - Operator: __init__: words_num_filter args: {'lang': {'default': 'en', 'type': 'str'}, 'max_num': {'default': 9007199254740991, 'type': 'int'}, 'min_num': {'default': 10, 'type': 'int'}, 'tokenization': {'default': False, 'type': 'bool'}}\n"
     ]
    }
   ],
   "source": [
    "from operator_pool import OperatorPool\n",
    "\n",
    "# op_pool = OperatorPool(config_path=\"./configs/default_ops.yaml\")\n",
    "op_pool = OperatorPool(config_path=\"./configs/all_ops.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62585ea12b7784a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T07:01:24.191947Z",
     "start_time": "2025-06-18T07:01:24.188808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alphanumeric_filter'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access op with index\n",
    "op_pool[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce31f766ba57ee8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T07:01:24.205330Z",
     "start_time": "2025-06-18T07:01:24.203145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Filter to keep samples with alphabet/numeric ratio within a specific range.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access op with name as key\n",
    "op_pool[\"alphanumeric_filter\"].desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de528a6c4da4ed0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T07:01:24.215161Z",
     "start_time": "2025-06-18T07:01:24.213549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphanumeric_filter\n",
      "audio_add_gaussian_noise_mapper\n",
      "audio_duration_filter\n",
      "audio_nmf_snr_filter\n",
      "audio_size_filter\n",
      "average_line_length_filter\n",
      "character_repetition_filter\n",
      "chinese_convert_mapper\n",
      "clean_copyright_mapper\n",
      "clean_html_mapper\n",
      "document_deduplicator\n",
      "expand_macro_mapper\n",
      "extract_tables_from_html_mapper\n",
      "fix_unicode_mapper\n",
      "human_preference_annotation_mapper\n",
      "image_aesthetics_filter\n",
      "image_aspect_ratio_filter\n",
      "image_blur_mapper\n",
      "image_deduplicator\n",
      "image_face_count_filter\n",
      "image_face_ratio_filter\n",
      "image_nsfw_filter\n",
      "image_segment_mapper\n",
      "image_shape_filter\n",
      "image_size_filter\n",
      "image_tagging_mapper\n",
      "image_text_matching_filter\n",
      "image_text_similarity_filter\n",
      "image_watermark_filter\n",
      "maximum_line_length_filter\n",
      "mllm_mapper\n",
      "nlpaug_en_mapper\n",
      "nlpcda_zh_mapper\n",
      "perplexity_filter\n",
      "phrase_grounding_recall_filter\n",
      "punctuation_normalization_mapper\n",
      "python_file_mapper\n",
      "python_lambda_mapper\n",
      "ray_document_deduplicator\n",
      "ray_image_deduplicator\n",
      "ray_video_deduplicator\n",
      "remove_bibliography_mapper\n",
      "remove_header_mapper\n",
      "remove_long_words_mapper\n",
      "remove_non_chinese_character_mapper\n",
      "remove_repeat_sentences_mapper\n",
      "remove_table_text_mapper\n",
      "sentence_split_mapper\n",
      "special_characters_filter\n",
      "specified_numeric_field_filter\n",
      "text_action_filter\n",
      "text_entity_dependency_filter\n",
      "text_length_filter\n",
      "token_num_filter\n",
      "video_aesthetics_filter\n",
      "video_aspect_ratio_filter\n",
      "video_captioning_from_audio_mapper\n",
      "video_deduplicator\n",
      "video_duration_filter\n",
      "video_extract_frames_mapper\n",
      "video_face_blur_mapper\n",
      "video_frames_text_similarity_filter\n",
      "video_nsfw_filter\n",
      "video_resize_aspect_ratio_mapper\n",
      "video_resize_resolution_mapper\n",
      "video_resolution_filter\n",
      "video_split_by_duration_mapper\n",
      "video_split_by_key_frame_mapper\n",
      "video_tagging_from_audio_mapper\n",
      "video_tagging_from_frames_filter\n",
      "video_tagging_from_frames_mapper\n",
      "video_watermark_filter\n",
      "whitespace_normalization_mapper\n",
      "word_repetition_filter\n",
      "words_num_filter\n"
     ]
    }
   ],
   "source": [
    "# iteration\n",
    "for op_name in op_pool.pool:\n",
    "    print(op_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7323e558a41081aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T07:01:24.235485Z",
     "start_time": "2025-06-18T07:01:24.232404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphanumeric_filter': {'name': 'alphanumeric_filter',\n",
       "  'desc': 'Filter to keep samples with alphabet/numeric ratio within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'max_ratio': {'name': 'max_ratio',\n",
       "    'desc': \"max_ratio (<class 'float'>): The max filter ratio in alphanumeric op, samples will be filtered if their alphabet/numeric ratio exceeds this parameter.\",\n",
       "    'type': 'float',\n",
       "    'default': 9007199254740991.0,\n",
       "    'v': 9007199254740991.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_ratio': {'name': 'min_ratio',\n",
       "    'desc': \"min_ratio (<class 'float'>): The min filter ratio in alphanumeric op, samples will be filtered if their alphabet/numeric ratio is below this parameter.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.25,\n",
       "    'v': 0.25,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'tokenization': {'name': 'tokenization',\n",
       "    'desc': \"tokenization (<class 'bool'>): Whether to count the ratio of alphanumeric to the total number of tokens. if tokenization=False, it will count the ratio of alphanumeric to the total number of characters.\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'audio_add_gaussian_noise_mapper': {'name': 'audio_add_gaussian_noise_mapper',\n",
       "  'desc': 'Mapper to add gaussian noise to audio.',\n",
       "  'enabled': True,\n",
       "  'args': {'max_amplitude': {'name': 'max_amplitude',\n",
       "    'desc': \"max_amplitude (<class 'float'>):\",\n",
       "    'type': 'float',\n",
       "    'default': 0.015,\n",
       "    'v': 0.015,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_amplitude': {'name': 'min_amplitude',\n",
       "    'desc': \"min_amplitude (<class 'float'>):\",\n",
       "    'type': 'float',\n",
       "    'default': 0.001,\n",
       "    'v': 0.001,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'p': {'name': 'p',\n",
       "    'desc': \"p (<class 'float'>):\",\n",
       "    'type': 'float',\n",
       "    'default': 0.5,\n",
       "    'v': 0.5,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'audio_duration_filter': {'name': 'audio_duration_filter',\n",
       "  'desc': \"Keep data samples whose audios' durations are within a specified range.\",\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all audios. 'any': keep this sample if any audios meet the condition. 'all': keep this sample only if all audios meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_duration': {'name': 'max_duration',\n",
       "    'desc': \"max_duration (<class 'int'>): The max audio duration to keep samples in seconds. It's sys.maxsize by default.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_duration': {'name': 'min_duration',\n",
       "    'desc': \"min_duration (<class 'int'>): The min audio duration to keep samples in seconds. It's 0 by default.\",\n",
       "    'type': 'int',\n",
       "    'default': 0,\n",
       "    'v': 0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'audio_nmf_snr_filter': {'name': 'audio_nmf_snr_filter',\n",
       "  'desc': \"Keep data samples whose audios' SNRs (computed based on NMF) are within a specified range.\",\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all audios. 'any': keep this sample if any audios meet the condition. 'all': keep this sample only if all audios meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_snr': {'name': 'max_snr',\n",
       "    'desc': \"max_snr (<class 'float'>): The max audio SNR to keep samples in dB. It's sys.maxsize by default.\",\n",
       "    'type': 'float',\n",
       "    'default': 9007199254740991.0,\n",
       "    'v': 9007199254740991.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_snr': {'name': 'min_snr',\n",
       "    'desc': \"min_snr (<class 'float'>): The min audio SNR to keep samples in dB. It's 0 by default.\",\n",
       "    'type': 'int',\n",
       "    'default': 0,\n",
       "    'v': 0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'nmf_iter_num': {'name': 'nmf_iter_num',\n",
       "    'desc': \"nmf_iter_num (typing.Annotated[int, Gt(gt=0)]): The max number of iterations to run NMF. It's 500 in default.\",\n",
       "    'type': 'int',\n",
       "    'default': 500,\n",
       "    'v': 500,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'audio_size_filter': {'name': 'audio_size_filter',\n",
       "  'desc': 'Keep data samples whose audio size (in bytes/kb/MB/...) within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all audios. 'any': keep this sample if any audios meet the condition. 'all': keep this sample only if all audios meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_size': {'name': 'max_size',\n",
       "    'desc': 'max_size (<class \\'str\\'>): The max audio size to keep samples.  set to be \"1Tb\" by default, an approximate for un-limited case',\n",
       "    'type': 'str',\n",
       "    'default': '1TB',\n",
       "    'v': '1TB',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_size': {'name': 'min_size',\n",
       "    'desc': 'min_size (<class \\'str\\'>): The min audio size to keep samples.  set to be \"0\" by default for no size constraint',\n",
       "    'type': 'str',\n",
       "    'default': '0',\n",
       "    'v': '0',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'average_line_length_filter': {'name': 'average_line_length_filter',\n",
       "  'desc': 'Filter to keep samples with average line length within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'max_len': {'name': 'max_len',\n",
       "    'desc': \"max_len (<class 'int'>): The max filter length in this op, samples will be filtered if their average line length exceeds this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_len': {'name': 'min_len',\n",
       "    'desc': \"min_len (<class 'int'>): The min filter length in this op, samples will be filtered if their average line length is below this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 10,\n",
       "    'v': 10,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'character_repetition_filter': {'name': 'character_repetition_filter',\n",
       "  'desc': 'Filter to keep samples with char-level n-gram repetition ratio within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'max_ratio': {'name': 'max_ratio',\n",
       "    'desc': \"max_ratio (<class 'float'>): The max filter ratio in this op, samples will be filtered if their char-level n-gram repetition ratio exceeds this parameter.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.5,\n",
       "    'v': 0.5,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_ratio': {'name': 'min_ratio',\n",
       "    'desc': \"min_ratio (<class 'float'>): The min filter ratio in this op, samples will be filtered if their char-level n-gram repetition ratio is below this parameter.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.0,\n",
       "    'v': 0.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'rep_len': {'name': 'rep_len',\n",
       "    'desc': 'rep_len (typing.Annotated[int, Gt(gt=0)]): Repetition length for char-level n-gram.',\n",
       "    'type': 'int',\n",
       "    'default': 10,\n",
       "    'v': 10,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'chinese_convert_mapper': {'name': 'chinese_convert_mapper',\n",
       "  'desc': 'Mapper to convert Chinese between Traditional Chinese, Simplified Chinese and Japanese Kanji.',\n",
       "  'enabled': True,\n",
       "  'args': {'mode': {'name': 'mode',\n",
       "    'desc': \"mode (<class 'str'>): Choose the mode to convert Chinese:  s2t: Simplified Chinese to Traditional Chinese,  t2s: Traditional Chinese to Simplified Chinese,  s2tw: Simplified Chinese to Traditional Chinese (Taiwan Standard),  tw2s: Traditional Chinese (Taiwan Standard) to Simplified Chinese,  s2hk: Simplified Chinese to Traditional Chinese (Hong Kong variant),  hk2s: Traditional Chinese (Hong Kong variant) to Simplified Chinese,  s2twp: Simplified Chinese to Traditional Chinese (Taiwan Standard) with Taiwanese idiom,  tw2sp: Traditional Chinese (Taiwan Standard) to Simplified Chinese with Mainland Chinese idiom,  t2tw: Traditional Chinese to Traditional Chinese (Taiwan Standard),  tw2t: Traditional Chinese (Taiwan standard) to Traditional Chinese,  hk2t: Traditional Chinese (Hong Kong variant) to Traditional Chinese,  t2hk: Traditional Chinese to Traditional Chinese (Hong Kong variant),  t2jp: Traditional Chinese Characters (Kyūjitai) to New Japanese Kanji,  jp2t: New Japanese Kanji (Shinjitai) to Traditional Chinese Characters,\",\n",
       "    'type': 'str',\n",
       "    'default': 's2t',\n",
       "    'v': 's2t',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'clean_copyright_mapper': {'name': 'clean_copyright_mapper',\n",
       "  'desc': 'Mapper to clean copyright comments at the beginning of the text samples.',\n",
       "  'enabled': True,\n",
       "  'args': {},\n",
       "  'stats': {}},\n",
       " 'clean_html_mapper': {'name': 'clean_html_mapper',\n",
       "  'desc': 'Mapper to clean html code in text samples.',\n",
       "  'enabled': True,\n",
       "  'args': {},\n",
       "  'stats': {}},\n",
       " 'document_deduplicator': {'name': 'document_deduplicator',\n",
       "  'desc': 'Deduplicator to deduplicate samples at document-level using exact matching.  Using md5 hash to deduplicate samples.',\n",
       "  'enabled': True,\n",
       "  'args': {'ignore_non_character': {'name': 'ignore_non_character',\n",
       "    'desc': \"ignore_non_character (<class 'bool'>): Whether to ignore non-alphabet characters, including whitespaces, digits, and punctuations\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'lowercase': {'name': 'lowercase',\n",
       "    'desc': \"lowercase (<class 'bool'>): Whether to convert sample text to lower case\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'expand_macro_mapper': {'name': 'expand_macro_mapper',\n",
       "  'desc': 'Mapper to expand macro definitions in the document body of Latex samples.',\n",
       "  'enabled': True,\n",
       "  'args': {},\n",
       "  'stats': {}},\n",
       " 'extract_tables_from_html_mapper': {'name': 'extract_tables_from_html_mapper',\n",
       "  'desc': 'Mapper to extract tables from HTML content.',\n",
       "  'enabled': True,\n",
       "  'args': {'include_header': {'name': 'include_header',\n",
       "    'desc': \"include_header (<class 'bool'>): If True, includes the table header; otherwise, excludes it. This parameter is effective only when `retain_html_tags` is False and applies solely to the extracted table content.\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'retain_html_tags': {'name': 'retain_html_tags',\n",
       "    'desc': \"retain_html_tags (<class 'bool'>): If True, retains HTML tags in the tables; otherwise, removes them.\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'tables_field_name': {'name': 'tables_field_name',\n",
       "    'desc': \"tables_field_name (<class 'str'>): Field name to store the extracted tables.\",\n",
       "    'type': 'str',\n",
       "    'default': 'html_tables',\n",
       "    'v': 'html_tables',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'fix_unicode_mapper': {'name': 'fix_unicode_mapper',\n",
       "  'desc': 'Mapper to fix unicode errors in text samples.',\n",
       "  'enabled': True,\n",
       "  'args': {'normalization': {'name': 'normalization',\n",
       "    'desc': \"normalization (<class 'str'>): the specified form of Unicode normalization mode, which can be one of ['NFC', 'NFKC', 'NFD', and 'NFKD'], default 'NFC'.\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'human_preference_annotation_mapper': {'name': 'human_preference_annotation_mapper',\n",
       "  'desc': 'Operator for human preference annotation using Label Studio.',\n",
       "  'enabled': True,\n",
       "  'args': {'answer1_key': {'name': 'answer1_key',\n",
       "    'desc': \"answer1_key (<class 'str'>):\",\n",
       "    'type': 'str',\n",
       "    'default': 'answer1',\n",
       "    'v': 'answer1',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'answer2_key': {'name': 'answer2_key',\n",
       "    'desc': \"answer2_key (<class 'str'>):\",\n",
       "    'type': 'str',\n",
       "    'default': 'answer2',\n",
       "    'v': 'answer2',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'chosen_key': {'name': 'chosen_key',\n",
       "    'desc': \"chosen_key (<class 'str'>):\",\n",
       "    'type': 'str',\n",
       "    'default': 'chosen',\n",
       "    'v': 'chosen',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'label_config_file': {'name': 'label_config_file',\n",
       "    'desc': \"label_config_file (<class 'str'>):\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'prompt_key': {'name': 'prompt_key',\n",
       "    'desc': \"prompt_key (<class 'str'>):\",\n",
       "    'type': 'str',\n",
       "    'default': 'prompt',\n",
       "    'v': 'prompt',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'rejected_key': {'name': 'rejected_key',\n",
       "    'desc': \"rejected_key (<class 'str'>):\",\n",
       "    'type': 'str',\n",
       "    'default': 'rejected',\n",
       "    'v': 'rejected',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_aesthetics_filter': {'name': 'image_aesthetics_filter',\n",
       "  'desc': 'Filter to keep samples with aesthetics scores within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): Keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'hf_scorer_model': {'name': 'hf_scorer_model',\n",
       "    'desc': \"hf_scorer_model (<class 'str'>): Huggingface model name for the aesthetics predictor. By default, we will use 'shunk031/aesthetics-predictor-v2-sac-logos-ava1-l14-linearMSE', refer to pypi.org/project/simple-aesthetics-predictor\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_score': {'name': 'max_score',\n",
       "    'desc': \"max_score (<class 'float'>): Max score for the predicted aesthetics in an image.\",\n",
       "    'type': 'float',\n",
       "    'default': 1.0,\n",
       "    'v': 1.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_score': {'name': 'min_score',\n",
       "    'desc': \"min_score (<class 'float'>): Min score for the predicted aesthetics in an image.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.5,\n",
       "    'v': 0.5,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': \"trust_remote_code (<class 'bool'>):\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_aspect_ratio_filter': {'name': 'image_aspect_ratio_filter',\n",
       "  'desc': 'Filter to keep samples with image aspect ratio within a specific range. AspectRatio = W / H.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_ratio': {'name': 'max_ratio',\n",
       "    'desc': \"max_ratio (<class 'float'>): The max aspect ratio to keep samples.\",\n",
       "    'type': 'float',\n",
       "    'default': 3.0,\n",
       "    'v': 3.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_ratio': {'name': 'min_ratio',\n",
       "    'desc': \"min_ratio (<class 'float'>): The min aspect ratio to keep samples.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.333,\n",
       "    'v': 0.333,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_blur_mapper': {'name': 'image_blur_mapper',\n",
       "  'desc': 'Mapper to blur images.',\n",
       "  'enabled': True,\n",
       "  'args': {'blur_type': {'name': 'blur_type',\n",
       "    'desc': \"blur_type (<class 'str'>): Type of blur kernel, including ['mean', 'box', 'gaussian'].\",\n",
       "    'type': 'str',\n",
       "    'default': 'gaussian',\n",
       "    'v': 'gaussian',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'p': {'name': 'p',\n",
       "    'desc': \"p (<class 'float'>): Probability of the image being blurred.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.2,\n",
       "    'v': 0.2,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'radius': {'name': 'radius',\n",
       "    'desc': \"radius (<class 'float'>): Radius of blur kernel.\",\n",
       "    'type': 'int',\n",
       "    'default': 2,\n",
       "    'v': 2,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_deduplicator': {'name': 'image_deduplicator',\n",
       "  'desc': 'Deduplicator to deduplicate samples at document-level using exact matching of images between documents.',\n",
       "  'enabled': True,\n",
       "  'args': {'consider_text': {'name': 'consider_text',\n",
       "    'desc': \"consider_text (<class 'bool'>): whether to consider text hash together with image hash when applying deduplication.\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'method': {'name': 'method',\n",
       "    'desc': \"method (<class 'str'>): hash method for image\",\n",
       "    'type': 'str',\n",
       "    'default': 'phash',\n",
       "    'v': 'phash',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_face_count_filter': {'name': 'image_face_count_filter',\n",
       "  'desc': 'Filter to keep samples with the number of faces within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): Keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'cv_classifier': {'name': 'cv_classifier',\n",
       "    'desc': \"cv_classifier (<class 'str'>): OpenCV classifier path for face detection. By default, we will use 'haarcascade_frontalface_alt.xml'.\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_face_count': {'name': 'max_face_count',\n",
       "    'desc': \"max_face_count (<class 'int'>): Maximum number of faces required for samples.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_face_count': {'name': 'min_face_count',\n",
       "    'desc': \"min_face_count (<class 'int'>): Minimum number of faces required for samples.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_face_ratio_filter': {'name': 'image_face_ratio_filter',\n",
       "  'desc': 'Filter to keep samples with face area ratios within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): Keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'cv_classifier': {'name': 'cv_classifier',\n",
       "    'desc': \"cv_classifier (<class 'str'>): OpenCV classifier path for face detection. By default, we will use 'haarcascade_frontalface_alt.xml'.\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_ratio': {'name': 'max_ratio',\n",
       "    'desc': \"max_ratio (<class 'float'>): Max ratio for the largest face area in an image.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.4,\n",
       "    'v': 0.4,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_ratio': {'name': 'min_ratio',\n",
       "    'desc': \"min_ratio (<class 'float'>): Min ratio for the largest face area in an image.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.0,\n",
       "    'v': 0.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_nsfw_filter': {'name': 'image_nsfw_filter',\n",
       "  'desc': 'Filter to keep samples whose images have low nsfw scores.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'hf_nsfw_model': {'name': 'hf_nsfw_model',\n",
       "    'desc': \"hf_nsfw_model (<class 'str'>): nsfw detection model name on huggingface.\",\n",
       "    'type': 'str',\n",
       "    'default': 'Falconsai/nsfw_image_detection',\n",
       "    'v': 'Falconsai/nsfw_image_detection',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_score': {'name': 'max_score',\n",
       "    'desc': \"max_score (<class 'float'>): the nsfw score threshold for samples. range from 0 to 1. Samples with nsfw score less than this threshold will be kept.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.5,\n",
       "    'v': 0.5,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': \"trust_remote_code (<class 'bool'>):\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_segment_mapper': {'name': 'image_segment_mapper',\n",
       "  'desc': 'Perform segment-anything on images and return the bounding boxes.',\n",
       "  'enabled': True,\n",
       "  'args': {'conf': {'name': 'conf',\n",
       "    'desc': 'conf (unknown): confidence score threshold',\n",
       "    'type': 'float',\n",
       "    'default': 0.05,\n",
       "    'v': 0.05,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'imgsz': {'name': 'imgsz',\n",
       "    'desc': 'imgsz (unknown): resolution for image resizing',\n",
       "    'type': 'int',\n",
       "    'default': 1024,\n",
       "    'v': 1024,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'iou': {'name': 'iou',\n",
       "    'desc': 'iou (unknown): IoU (Intersection over Union) score threshold',\n",
       "    'type': 'float',\n",
       "    'default': 0.5,\n",
       "    'v': 0.5,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'model_path': {'name': 'model_path',\n",
       "    'desc': \"model_path (unknown): the path to the FastSAM model. Model name should be one of ['FastSAM-x.pt', 'FastSAM-s.pt'].\",\n",
       "    'type': 'str',\n",
       "    'default': 'FastSAM-x.pt',\n",
       "    'v': 'FastSAM-x.pt',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_shape_filter': {'name': 'image_shape_filter',\n",
       "  'desc': 'Filter to keep samples with image shape (w, h) within specific ranges.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_height': {'name': 'max_height',\n",
       "    'desc': \"max_height (<class 'int'>): The max height to keep samples.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_width': {'name': 'max_width',\n",
       "    'desc': \"max_width (<class 'int'>): The max width to keep samples.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_height': {'name': 'min_height',\n",
       "    'desc': \"min_height (<class 'int'>): The min height to keep samples.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_width': {'name': 'min_width',\n",
       "    'desc': \"min_width (<class 'int'>): The min width to keep samples.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_size_filter': {'name': 'image_size_filter',\n",
       "  'desc': 'Keep data samples whose image size (in Bytes/KB/MB/...) within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_size': {'name': 'max_size',\n",
       "    'desc': 'max_size (<class \\'str\\'>): The max image size to keep samples.  set to be \"1TB\" by default, an approximate for un-limited case',\n",
       "    'type': 'str',\n",
       "    'default': '1TB',\n",
       "    'v': '1TB',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_size': {'name': 'min_size',\n",
       "    'desc': 'min_size (<class \\'str\\'>): The min image size to keep samples.  set to be \"0\" by default for no size constraint',\n",
       "    'type': 'str',\n",
       "    'default': '0',\n",
       "    'v': '0',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_tagging_mapper': {'name': 'image_tagging_mapper',\n",
       "  'desc': 'Mapper to generate image tags.',\n",
       "  'enabled': True,\n",
       "  'args': {'tag_field_name': {'name': 'tag_field_name',\n",
       "    'desc': 'tag_field_name (<class \\'str\\'>): the field name to store the tags. It\\'s \"image_tags\" in default.',\n",
       "    'type': 'str',\n",
       "    'default': 'image_tags',\n",
       "    'v': 'image_tags',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_text_matching_filter': {'name': 'image_text_matching_filter',\n",
       "  'desc': 'Filter to keep samples those matching score between image and text within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'hf_blip': {'name': 'hf_blip',\n",
       "    'desc': \"hf_blip (<class 'str'>): blip model name on huggingface to compute the matching score between image and text.\",\n",
       "    'type': 'str',\n",
       "    'default': 'Salesforce/blip-itm-base-coco',\n",
       "    'v': 'Salesforce/blip-itm-base-coco',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'horizontal_flip': {'name': 'horizontal_flip',\n",
       "    'desc': \"horizontal_flip (<class 'bool'>): Flip image horizontally (left to right).\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_score': {'name': 'max_score',\n",
       "    'desc': \"max_score (<class 'float'>): The max matching score to keep samples.\",\n",
       "    'type': 'float',\n",
       "    'default': 1.0,\n",
       "    'v': 1.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_score': {'name': 'min_score',\n",
       "    'desc': \"min_score (<class 'float'>): The min matching score to keep samples.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.003,\n",
       "    'v': 0.003,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'reduce_mode': {'name': 'reduce_mode',\n",
       "    'desc': \"reduce_mode (<class 'str'>): reduce mode when one text corresponds to multiple images in a chunk. 'avg': Take the average of multiple values 'max': Take the max of multiple values 'min': Take the min of multiple values\",\n",
       "    'type': 'str',\n",
       "    'default': 'avg',\n",
       "    'v': 'avg',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': \"trust_remote_code (<class 'bool'>):\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'vertical_flip': {'name': 'vertical_flip',\n",
       "    'desc': \"vertical_flip (<class 'bool'>): Flip image vertically (top to bottom).\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_text_similarity_filter': {'name': 'image_text_similarity_filter',\n",
       "  'desc': 'Filter to keep samples those similarities between image and text within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'hf_clip': {'name': 'hf_clip',\n",
       "    'desc': \"hf_clip (<class 'str'>): clip model name on huggingface to compute the similarity between image and text.\",\n",
       "    'type': 'str',\n",
       "    'default': 'openai/clip-vit-base-patch32',\n",
       "    'v': 'openai/clip-vit-base-patch32',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'horizontal_flip': {'name': 'horizontal_flip',\n",
       "    'desc': \"horizontal_flip (<class 'bool'>): Flip image horizontally (left to right).\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_score': {'name': 'max_score',\n",
       "    'desc': \"max_score (<class 'float'>): The max similarity to keep samples.\",\n",
       "    'type': 'float',\n",
       "    'default': 1.0,\n",
       "    'v': 1.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_score': {'name': 'min_score',\n",
       "    'desc': \"min_score (<class 'float'>): The min similarity to keep samples.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.1,\n",
       "    'v': 0.1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'reduce_mode': {'name': 'reduce_mode',\n",
       "    'desc': \"reduce_mode (<class 'str'>): reduce mode when one text corresponds to multiple images in a chunk. 'avg': Take the average of multiple values 'max': Take the max of multiple values 'min': Take the min of multiple values\",\n",
       "    'type': 'str',\n",
       "    'default': 'avg',\n",
       "    'v': 'avg',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': \"trust_remote_code (<class 'bool'>):\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'vertical_flip': {'name': 'vertical_flip',\n",
       "    'desc': \"vertical_flip (<class 'bool'>): Flip image vertically (top to bottom).\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'image_watermark_filter': {'name': 'image_watermark_filter',\n",
       "  'desc': 'Filter to keep samples whose images have no watermark with high probability.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'hf_watermark_model': {'name': 'hf_watermark_model',\n",
       "    'desc': \"hf_watermark_model (<class 'str'>): watermark detection model name on huggingface.\",\n",
       "    'type': 'str',\n",
       "    'default': 'amrul-hzz/watermark_detector',\n",
       "    'v': 'amrul-hzz/watermark_detector',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'prob_threshold': {'name': 'prob_threshold',\n",
       "    'desc': \"prob_threshold (<class 'float'>): the predicted watermark probability threshold for samples. range from 0 to 1. Samples with watermark probability less than this threshold will be kept.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.8,\n",
       "    'v': 0.8,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': \"trust_remote_code (<class 'bool'>):\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'maximum_line_length_filter': {'name': 'maximum_line_length_filter',\n",
       "  'desc': 'Filter to keep samples with maximum line length within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'max_len': {'name': 'max_len',\n",
       "    'desc': \"max_len (<class 'int'>): The max filter length in this op, samples will be filtered if their maximum line length exceeds this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_len': {'name': 'min_len',\n",
       "    'desc': \"min_len (<class 'int'>): The min filter length in this op, samples will be filtered if their maximum line length is below this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 10,\n",
       "    'v': 10,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'mllm_mapper': {'name': 'mllm_mapper',\n",
       "  'desc': 'Mapper to use MLLMs for visual question answering tasks. Recommended model list: [     llava-hf/llava-v1.6-vicuna-7b-hf,     Qwen/Qwen2-VL-7B-Instruct, ]',\n",
       "  'enabled': True,\n",
       "  'args': {'hf_model': {'name': 'hf_model',\n",
       "    'desc': \"hf_model (<class 'str'>): hugginface model id.\",\n",
       "    'type': 'str',\n",
       "    'default': 'llava-hf/llava-v1.6-vicuna-7b-hf',\n",
       "    'v': 'llava-hf/llava-v1.6-vicuna-7b-hf',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_new_tokens': {'name': 'max_new_tokens',\n",
       "    'desc': 'max_new_tokens (unknown): the maximum number of new tokens generated by the model.',\n",
       "    'type': 'int',\n",
       "    'default': 256,\n",
       "    'v': 256,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'num_beams': {'name': 'num_beams',\n",
       "    'desc': 'num_beams (unknown): the larger the beam search size, the higher             the quality of the generated text.',\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'temperature': {'name': 'temperature',\n",
       "    'desc': 'temperature (unknown): used to control the randomness of             generated text. The higher the temperature, the more                 random and creative the generated text will be.',\n",
       "    'type': 'float',\n",
       "    'default': 0.2,\n",
       "    'v': 0.2,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'top_p': {'name': 'top_p',\n",
       "    'desc': 'top_p (unknown): randomly select the next word from the group             of words whose cumulative probability reaches p.',\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'nlpaug_en_mapper': {'name': 'nlpaug_en_mapper',\n",
       "  'desc': 'Mapper to simply augment samples in English based on nlpaug library.',\n",
       "  'enabled': True,\n",
       "  'args': {'aug_num': {'name': 'aug_num',\n",
       "    'desc': \"aug_num (typing.Annotated[int, Gt(gt=0)]): number of augmented samples to be generated. If `sequential` is True, there will be total aug_num augmented samples generated. If it's False, there will be (aug_num * #opened_aug_method) augmented samples generated.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'delete_random_char': {'name': 'delete_random_char',\n",
       "    'desc': 'delete_random_char (<class \\'bool\\'>): whether to open the augmentation method of deleting random characters from the original texts. e.g. \"I love LLM\" --> \"I oe LLM\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'delete_random_word': {'name': 'delete_random_word',\n",
       "    'desc': 'delete_random_word (<class \\'bool\\'>): whether to open the augmentation method of deleting random words from the original texts. e.g. \"I love LLM\" --> \"I LLM\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'insert_random_char': {'name': 'insert_random_char',\n",
       "    'desc': 'insert_random_char (<class \\'bool\\'>): whether to open the augmentation method of inserting random characters into the original texts. e.g. \"I love LLM\" --> \"I ^lKove LLM\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'keep_original_sample': {'name': 'keep_original_sample',\n",
       "    'desc': \"keep_original_sample (<class 'bool'>): whether to keep the original sample. If it's set to False, there will be only generated texts in the final datasets and the original texts will be removed. It's True in default.\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'keyboard_error_char': {'name': 'keyboard_error_char',\n",
       "    'desc': 'keyboard_error_char (<class \\'bool\\'>): whether to open the augmentation method of simulating the keyboard error for characters in the original texts. e.g. \"I love LLM\" --> \"I ;ov4 LLM\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'ocr_error_char': {'name': 'ocr_error_char',\n",
       "    'desc': 'ocr_error_char (<class \\'bool\\'>): whether to open the augmentation method of simulating the OCR error for characters in the original texts. e.g. \"I love LLM\" --> \"I 10ve LLM\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'sequential': {'name': 'sequential',\n",
       "    'desc': \"sequential (<class 'bool'>): whether combine all augmentation methods to a sequence. If it's True, a sample will be augmented by all opened augmentation methods sequentially. If it's False, each opened augmentation method would generate its augmented samples independently.\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'spelling_error_word': {'name': 'spelling_error_word',\n",
       "    'desc': 'spelling_error_word (<class \\'bool\\'>): whether to open the augmentation method of simulating the spelling error for words in the original texts. e.g. \"I love LLM\" --> \"Ai love LLM\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'split_random_word': {'name': 'split_random_word',\n",
       "    'desc': 'split_random_word (<class \\'bool\\'>): whether to open the augmentation method of splitting words randomly with whitespaces in the original texts. e.g. \"I love LLM\" --> \"I love LL M\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'swap_random_char': {'name': 'swap_random_char',\n",
       "    'desc': 'swap_random_char (<class \\'bool\\'>): whether to open the augmentation method of swapping random contiguous characters in the original texts. e.g. \"I love LLM\" --> \"I ovle LLM\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'swap_random_word': {'name': 'swap_random_word',\n",
       "    'desc': 'swap_random_word (<class \\'bool\\'>): whether to open the augmentation method of swapping random contiguous words in the original texts. e.g. \"I love LLM\" --> \"Love I LLM\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'nlpcda_zh_mapper': {'name': 'nlpcda_zh_mapper',\n",
       "  'desc': 'Mapper to simply augment samples in Chinese based on nlpcda library.',\n",
       "  'enabled': True,\n",
       "  'args': {'aug_num': {'name': 'aug_num',\n",
       "    'desc': \"aug_num (typing.Annotated[int, Gt(gt=0)]): number of augmented samples to be generated. If `sequential` is True, there will be total aug_num augmented samples generated. If it's False, there will be (aug_num * #opened_aug_method) augmented samples generated.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'delete_random_char': {'name': 'delete_random_char',\n",
       "    'desc': 'delete_random_char (<class \\'bool\\'>): whether to open the augmentation method of deleting random characters from the original texts. e.g. \"这里一共有5种不同的数据增强方法\" --> \"这里一共有5种不同的数据增强\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'keep_original_sample': {'name': 'keep_original_sample',\n",
       "    'desc': \"keep_original_sample (<class 'bool'>): whether to keep the original sample. If it's set to False, there will be only generated texts in the final datasets and the original texts will be removed. It's True in default.\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'replace_equivalent_num': {'name': 'replace_equivalent_num',\n",
       "    'desc': 'replace_equivalent_num (<class \\'bool\\'>): whether to open the augmentation method of replacing random numbers with their equivalent representations in the original texts. **Notice**: Only for numbers for now. e.g. \"这里一共有5种不同的数据增强方法\" --> \"这里一共有伍种不同的数据增强方法\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'replace_homophone_char': {'name': 'replace_homophone_char',\n",
       "    'desc': 'replace_homophone_char (<class \\'bool\\'>): whether to open the augmentation method of replacing random characters with their homophones in the original texts. e.g. \"这里一共有5种不同的数据增强方法\" --> \"这里一共有5种不同的濖据增强方法\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'replace_similar_word': {'name': 'replace_similar_word',\n",
       "    'desc': 'replace_similar_word (<class \\'bool\\'>): whether to open the augmentation method of replacing random words with their similar words in the original texts. e.g. \"这里一共有5种不同的数据增强方法\" --> \"这边一共有5种不同的数据增强方法\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'sequential': {'name': 'sequential',\n",
       "    'desc': \"sequential (<class 'bool'>): whether combine all augmentation methods to a sequence. If it's True, a sample will be augmented by all opened augmentation methods sequentially. If it's False, each opened augmentation method would generate its augmented samples independently.\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'swap_random_char': {'name': 'swap_random_char',\n",
       "    'desc': 'swap_random_char (<class \\'bool\\'>): whether to open the augmentation method of swapping random contiguous characters in the original texts. e.g. \"这里一共有5种不同的数据增强方法\" --> \"这里一共有5种不同的数据强增方法\"',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'perplexity_filter': {'name': 'perplexity_filter',\n",
       "  'desc': 'Filter to keep samples with perplexity score less than a specific max value.',\n",
       "  'enabled': True,\n",
       "  'args': {'lang': {'name': 'lang',\n",
       "    'desc': \"lang (<class 'str'>): Compute perplexity for samples in which language.\",\n",
       "    'type': 'str',\n",
       "    'default': 'en',\n",
       "    'v': 'en',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_ppl': {'name': 'max_ppl',\n",
       "    'desc': \"max_ppl (<class 'float'>): The max filter perplexity in this op, samples will be filtered if their perplexity exceeds this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 1500,\n",
       "    'v': 1500,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'phrase_grounding_recall_filter': {'name': 'phrase_grounding_recall_filter',\n",
       "  'desc': 'Filter to keep samples whose locating recalls of phrases extracted from text in the images are within a specified range.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all images. 'any': keep this sample if any images meet the condition. 'all': keep this sample only if all images meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'conf_thr': {'name': 'conf_thr',\n",
       "    'desc': \"conf_thr (<class 'float'>): the confidence score threshold for removing low-confidence bboxes. If the confidence score of a predicted bbox is lower than the threshold, this bbox will be removed. Default: 0.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.0,\n",
       "    'v': 0.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'hf_owlvit': {'name': 'hf_owlvit',\n",
       "    'desc': \"hf_owlvit (<class 'str'>): Owl-ViT model name on huggingface to locate the phrases extracted from the text.\",\n",
       "    'type': 'str',\n",
       "    'default': 'google/owlvit-base-patch32',\n",
       "    'v': 'google/owlvit-base-patch32',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'horizontal_flip': {'name': 'horizontal_flip',\n",
       "    'desc': \"horizontal_flip (<class 'bool'>): Flip image horizontally (left to right).\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'iou_thr': {'name': 'iou_thr',\n",
       "    'desc': \"iou_thr (<class 'float'>): the IoU threshold for NMS-like post-process. If two predicted bboxes are overlap with an IoU larger than this threshold, the bbox with less confidence will be removed. Default: 0.5.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.5,\n",
       "    'v': 0.5,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'large_area_ratio_thr': {'name': 'large_area_ratio_thr',\n",
       "    'desc': \"large_area_ratio_thr (<class 'float'>): the area ratio threshold for filtering out those large predicted bboxes. If the area of a predicted bbox accounts for more than this ratio threshold of the whole image area, this bbox will be removed. Default: 0.95.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.95,\n",
       "    'v': 0.95,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_recall': {'name': 'max_recall',\n",
       "    'desc': \"max_recall (<class 'float'>): The max phrase grounding recall to keep samples.\",\n",
       "    'type': 'float',\n",
       "    'default': 1.0,\n",
       "    'v': 1.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_recall': {'name': 'min_recall',\n",
       "    'desc': \"min_recall (<class 'float'>): The min phrase grounding recall to keep samples.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.1,\n",
       "    'v': 0.1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'reduce_mode': {'name': 'reduce_mode',\n",
       "    'desc': \"reduce_mode (<class 'str'>): reduce mode when one text corresponds to multiple images in a chunk. 'avg': Take the average of multiple values 'max': Take the max of multiple values 'min': Take the min of multiple values\",\n",
       "    'type': 'str',\n",
       "    'default': 'avg',\n",
       "    'v': 'avg',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': \"trust_remote_code (<class 'bool'>):\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'vertical_flip': {'name': 'vertical_flip',\n",
       "    'desc': \"vertical_flip (<class 'bool'>): Flip image vertically (top to bottom).\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'punctuation_normalization_mapper': {'name': 'punctuation_normalization_mapper',\n",
       "  'desc': 'Mapper to normalize unicode punctuations to English punctuations in text samples.',\n",
       "  'enabled': True,\n",
       "  'args': {},\n",
       "  'stats': {}},\n",
       " 'python_file_mapper': {'name': 'python_file_mapper',\n",
       "  'desc': 'Mapper for executing Python function defined in a file.',\n",
       "  'enabled': True,\n",
       "  'args': {'batched': {'name': 'batched',\n",
       "    'desc': \"batched (<class 'bool'>): A boolean indicating whether to process input data in batches.\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'file_path': {'name': 'file_path',\n",
       "    'desc': \"file_path (<class 'str'>): The path to the Python file containing the function to be executed.\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'function_name': {'name': 'function_name',\n",
       "    'desc': \"function_name (<class 'str'>): The name of the function defined in the file to be executed.\",\n",
       "    'type': 'str',\n",
       "    'default': 'process_single',\n",
       "    'v': 'process_single',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'python_lambda_mapper': {'name': 'python_lambda_mapper',\n",
       "  'desc': 'Mapper for executing Python lambda function on data samples.',\n",
       "  'enabled': True,\n",
       "  'args': {'batched': {'name': 'batched',\n",
       "    'desc': \"batched (<class 'bool'>): A boolean indicating whether to process input data in batches.\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'lambda_str': {'name': 'lambda_str',\n",
       "    'desc': \"lambda_str (<class 'str'>): A string representation of the lambda function to be executed on data samples. If empty, the identity function is used.\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'ray_document_deduplicator': {'name': 'ray_document_deduplicator',\n",
       "  'desc': 'Deduplicator to deduplicate samples at document-level using exact matching.',\n",
       "  'enabled': True,\n",
       "  'args': {'backend': {'name': 'backend',\n",
       "    'desc': \"backend (<class 'str'>): the backend for dedup, either 'ray_actor' or 'redis'\",\n",
       "    'type': 'str',\n",
       "    'default': 'ray_actor',\n",
       "    'v': 'ray_actor',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'ignore_non_character': {'name': 'ignore_non_character',\n",
       "    'desc': \"ignore_non_character (<class 'bool'>): Whether to ignore non-alphabet characters, including whitespaces, digits, and punctuations\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'lowercase': {'name': 'lowercase',\n",
       "    'desc': \"lowercase (<class 'bool'>): Whether to convert sample text to lower case\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'redis_address': {'name': 'redis_address',\n",
       "    'desc': \"redis_address (<class 'str'>): the address of redis server\",\n",
       "    'type': 'str',\n",
       "    'default': 'redis://localhost:6379',\n",
       "    'v': 'redis://localhost:6379',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'ray_image_deduplicator': {'name': 'ray_image_deduplicator',\n",
       "  'desc': 'Deduplicator to deduplicate samples at document-level using exact matching of images between documents.',\n",
       "  'enabled': True,\n",
       "  'args': {'backend': {'name': 'backend',\n",
       "    'desc': \"backend (<class 'str'>): the backend for dedup, either 'ray_actor' or 'redis'\",\n",
       "    'type': 'str',\n",
       "    'default': 'ray_actor',\n",
       "    'v': 'ray_actor',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'method': {'name': 'method',\n",
       "    'desc': \"method (<class 'str'>):\",\n",
       "    'type': 'str',\n",
       "    'default': 'phash',\n",
       "    'v': 'phash',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'redis_address': {'name': 'redis_address',\n",
       "    'desc': \"redis_address (<class 'str'>): the address of redis server\",\n",
       "    'type': 'str',\n",
       "    'default': 'redis://localhost:6379',\n",
       "    'v': 'redis://localhost:6379',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'ray_video_deduplicator': {'name': 'ray_video_deduplicator',\n",
       "  'desc': 'Deduplicator to deduplicate samples at document-level using exact matching of videos between documents.',\n",
       "  'enabled': True,\n",
       "  'args': {'backend': {'name': 'backend',\n",
       "    'desc': \"backend (<class 'str'>): the backend for dedup, either 'ray_actor' or 'redis'\",\n",
       "    'type': 'str',\n",
       "    'default': 'ray_actor',\n",
       "    'v': 'ray_actor',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'redis_address': {'name': 'redis_address',\n",
       "    'desc': \"redis_address (<class 'str'>): the address of redis server\",\n",
       "    'type': 'str',\n",
       "    'default': 'redis://localhost:6379',\n",
       "    'v': 'redis://localhost:6379',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'remove_bibliography_mapper': {'name': 'remove_bibliography_mapper',\n",
       "  'desc': 'Mapper to remove bibliography at the end of documents in Latex samples.',\n",
       "  'enabled': True,\n",
       "  'args': {},\n",
       "  'stats': {}},\n",
       " 'remove_header_mapper': {'name': 'remove_header_mapper',\n",
       "  'desc': 'Mapper to remove headers at the beginning of documents in Latex samples.',\n",
       "  'enabled': True,\n",
       "  'args': {'drop_no_head': {'name': 'drop_no_head',\n",
       "    'desc': \"drop_no_head (<class 'bool'>): whether to drop sample texts without headers.\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'remove_long_words_mapper': {'name': 'remove_long_words_mapper',\n",
       "  'desc': 'Mapper to remove long words within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'max_len': {'name': 'max_len',\n",
       "    'desc': \"max_len (<class 'int'>): The max mapper word length in this op, words will be filtered if their length exceeds this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_len': {'name': 'min_len',\n",
       "    'desc': \"min_len (<class 'int'>): The min mapper word length in this op, words will be filtered if their length is below this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'remove_non_chinese_character_mapper': {'name': 'remove_non_chinese_character_mapper',\n",
       "  'desc': 'Mapper to remove non chinese Character in text samples.',\n",
       "  'enabled': True,\n",
       "  'args': {'keep_alphabet': {'name': 'keep_alphabet',\n",
       "    'desc': \"keep_alphabet (<class 'bool'>): whether to keep alphabet\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'keep_number': {'name': 'keep_number',\n",
       "    'desc': \"keep_number (<class 'bool'>): whether to keep number\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'keep_punc': {'name': 'keep_punc',\n",
       "    'desc': \"keep_punc (<class 'bool'>): whether to keep punctuation\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'remove_repeat_sentences_mapper': {'name': 'remove_repeat_sentences_mapper',\n",
       "  'desc': 'Mapper to remove repeat sentences in text samples.',\n",
       "  'enabled': True,\n",
       "  'args': {'ignore_special_character': {'name': 'ignore_special_character',\n",
       "    'desc': \"ignore_special_character (<class 'bool'>): Whether to ignore special characters when judging repeated sentences. Special characters are all characters except Chinese characters, letters and numbers.\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'lowercase': {'name': 'lowercase',\n",
       "    'desc': \"lowercase (<class 'bool'>): Whether to convert sample text to lower case\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_repeat_sentence_length': {'name': 'min_repeat_sentence_length',\n",
       "    'desc': \"min_repeat_sentence_length (<class 'int'>): Sentences shorter than this length will not be deduplicated. If ignore_special_character is set to True, then special characters are not included in this length.\",\n",
       "    'type': 'int',\n",
       "    'default': 2,\n",
       "    'v': 2,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'remove_table_text_mapper': {'name': 'remove_table_text_mapper',\n",
       "  'desc': 'Mapper to remove table texts from text samples.  Regular expression is used to remove tables in the range of column number of tables.',\n",
       "  'enabled': True,\n",
       "  'args': {'max_col': {'name': 'max_col',\n",
       "    'desc': 'max_col (typing.Annotated[int, FieldInfo(annotation=NoneType, required=True, metadata=[Ge(ge=2), Le(le=20)])]): The max number of columns of table to remove.',\n",
       "    'type': 'int',\n",
       "    'default': 20,\n",
       "    'v': 20,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_col': {'name': 'min_col',\n",
       "    'desc': 'min_col (typing.Annotated[int, FieldInfo(annotation=NoneType, required=True, metadata=[Ge(ge=2), Le(le=20)])]): The min number of columns of table to remove.',\n",
       "    'type': 'int',\n",
       "    'default': 2,\n",
       "    'v': 2,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'sentence_split_mapper': {'name': 'sentence_split_mapper',\n",
       "  'desc': 'Mapper to split text samples to sentences.',\n",
       "  'enabled': True,\n",
       "  'args': {'lang': {'name': 'lang',\n",
       "    'desc': \"lang (<class 'str'>): split sentence of text in which language.\",\n",
       "    'type': 'str',\n",
       "    'default': 'en',\n",
       "    'v': 'en',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'special_characters_filter': {'name': 'special_characters_filter',\n",
       "  'desc': 'Filter to keep samples with special-char ratio within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'max_ratio': {'name': 'max_ratio',\n",
       "    'desc': \"max_ratio (<class 'float'>): The max filter ratio in this op, samples will be filtered if their special-char ratio exceeds this parameter.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.25,\n",
       "    'v': 0.25,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_ratio': {'name': 'min_ratio',\n",
       "    'desc': \"min_ratio (<class 'float'>): The min filter ratio in this op, samples will be filtered if their special-char ratio is below this parameter.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.0,\n",
       "    'v': 0.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'specified_numeric_field_filter': {'name': 'specified_numeric_field_filter',\n",
       "  'desc': 'Filter based on specified numeric field information.  If the specified numeric information in the sample is not within the specified range, the sample will be filtered.',\n",
       "  'enabled': True,\n",
       "  'args': {'field_key': {'name': 'field_key',\n",
       "    'desc': \"field_key (<class 'str'>): Filter based on the specified numeric value corresponding to the target key. The target key corresponding to multi-level field information need to be separated by '.'.\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_value': {'name': 'max_value',\n",
       "    'desc': \"max_value (<class 'float'>): The max filter value in SpecifiedNumericField op, samples will be filtered if their specified numeric field value exceeds this parameter.\",\n",
       "    'type': 'float',\n",
       "    'default': 9007199254740991.0,\n",
       "    'v': 9007199254740991.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_value': {'name': 'min_value',\n",
       "    'desc': \"min_value (<class 'float'>): The min filter value in SpecifiedNumericField op, samples will be filtered if their specified numeric field value is below this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': -9007199254740991,\n",
       "    'v': -9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'text_action_filter': {'name': 'text_action_filter',\n",
       "  'desc': 'Filter to keep texts those contain actions in the text.',\n",
       "  'enabled': True,\n",
       "  'args': {'lang': {'name': 'lang',\n",
       "    'desc': \"lang (<class 'str'>): language of the text in the samples. 'en' for detection of actions in English and 'zh' for detection of actions in Chinese.\",\n",
       "    'type': 'str',\n",
       "    'default': 'en',\n",
       "    'v': 'en',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_action_num': {'name': 'min_action_num',\n",
       "    'desc': \"min_action_num (<class 'int'>):\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'text_entity_dependency_filter': {'name': 'text_entity_dependency_filter',\n",
       "  'desc': 'Identify the entities in the text which are independent with other token, and filter them. The text containing no entities will be omitted.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy. 'any': keep this sample if any object is dependent. 'all': keep this sample only if all images are dependent.\",\n",
       "    'type': 'str',\n",
       "    'default': 'all',\n",
       "    'v': 'all',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'lang': {'name': 'lang',\n",
       "    'desc': \"lang (<class 'str'>): language of the text in the samples. 'en' for detection of entities in English and 'zh' for detection of entities in Chinese.\",\n",
       "    'type': 'str',\n",
       "    'default': 'en',\n",
       "    'v': 'en',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_dependency_num': {'name': 'min_dependency_num',\n",
       "    'desc': \"min_dependency_num (<class 'int'>):\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'text_length_filter': {'name': 'text_length_filter',\n",
       "  'desc': 'Filter to keep samples with total text length within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'max_len': {'name': 'max_len',\n",
       "    'desc': \"max_len (<class 'int'>): The max text length in the filtering. samples will be filtered if their text length exceeds this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_len': {'name': 'min_len',\n",
       "    'desc': \"min_len (<class 'int'>): The min text length in the filtering. samples will be filtered if their text length is below this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 10,\n",
       "    'v': 10,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'token_num_filter': {'name': 'token_num_filter',\n",
       "  'desc': 'Filter to keep samples with total token number within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'hf_tokenizer': {'name': 'hf_tokenizer',\n",
       "    'desc': \"hf_tokenizer (<class 'str'>): the tokenizer name of Hugging Face tokenizers.\",\n",
       "    'type': 'str',\n",
       "    'default': 'EleutherAI/pythia-6.9b-deduped',\n",
       "    'v': 'EleutherAI/pythia-6.9b-deduped',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_num': {'name': 'max_num',\n",
       "    'desc': \"max_num (<class 'int'>): The max filter token number in this op, samples will be filtered if their token number exceeds this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_num': {'name': 'min_num',\n",
       "    'desc': \"min_num (<class 'int'>): The min filter token number in this op, samples will be filtered if their token number is below this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 10,\n",
       "    'v': 10,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_aesthetics_filter': {'name': 'video_aesthetics_filter',\n",
       "  'desc': 'Filter to keep data samples with aesthetics scores for specified frames in the videos within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): Keep this sample with 'any' or 'all' strategy of all videos. 'any': keep this sample if any videos meet the condition. 'all': keep this sample only if all videos meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'frame_num': {'name': 'frame_num',\n",
       "    'desc': 'frame_num (typing.Annotated[int, Gt(gt=0)]): the number of frames to be extracted uniformly from the video. Only works when frame_sampling_method is \"uniform\". If it\\'s 1, only the middle frame will be extracted. If it\\'s 2, only the first and the last frames will be extracted. If it\\'s larger than 2, in addition to the first and the last frames, other frames will be extracted uniformly within the video duration.',\n",
       "    'type': 'int',\n",
       "    'default': 3,\n",
       "    'v': 3,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'frame_sampling_method': {'name': 'frame_sampling_method',\n",
       "    'desc': 'frame_sampling_method (<class \\'str\\'>): sampling method of extracting frame images from the videos. Should be one of [\"all_keyframes\", \"uniform\"]. The former one extracts all key frames and the latter one extract specified number of frames uniformly from the video. Default: \"uniform\" with frame_num=3, considering that the number of keyframes can be large while their difference is usually small in terms of their aesthetics.',\n",
       "    'type': 'str',\n",
       "    'default': 'uniform',\n",
       "    'v': 'uniform',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'hf_scorer_model': {'name': 'hf_scorer_model',\n",
       "    'desc': \"hf_scorer_model (<class 'str'>): Huggingface model name for the aesthetics predictor. By default, we will use 'shunk031/aesthetics-predictor-v2-sac-logos-ava1-l14-linearMSE', refer to pypi.org/project/simple-aesthetics-predictor\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_score': {'name': 'max_score',\n",
       "    'desc': \"max_score (<class 'float'>): Max score for the predicted aesthetics in a video.\",\n",
       "    'type': 'float',\n",
       "    'default': 1.0,\n",
       "    'v': 1.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_score': {'name': 'min_score',\n",
       "    'desc': \"min_score (<class 'float'>): Min score for the predicted aesthetics in a video.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.4,\n",
       "    'v': 0.4,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'reduce_mode': {'name': 'reduce_mode',\n",
       "    'desc': \"reduce_mode (<class 'str'>): reduce mode when one sample corresponds to multiple frames, must be one of ['avg','max', 'min']. 'avg': Take the average of multiple values 'max': Take the max of multiple values 'min': Take the min of multiple values\",\n",
       "    'type': 'str',\n",
       "    'default': 'avg',\n",
       "    'v': 'avg',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': \"trust_remote_code (<class 'bool'>):\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_aspect_ratio_filter': {'name': 'video_aspect_ratio_filter',\n",
       "  'desc': 'Filter to keep samples with video aspect ratio within a specific range. AspectRatio = W / H.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all videos. 'any': keep this sample if any videos meet the condition. 'all': keep this sample only if all videos meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_ratio': {'name': 'max_ratio',\n",
       "    'desc': 'max_ratio (<class \\'str\\'>): The maximum aspect ratio to keep samples, supported format is a string, such as \"21:9\" or \"21/9\".',\n",
       "    'type': 'str',\n",
       "    'default': '21/9',\n",
       "    'v': '21/9',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_ratio': {'name': 'min_ratio',\n",
       "    'desc': 'min_ratio (<class \\'str\\'>): The minimum aspect ratio to keep samples, supported format is a string, such as \"9:21\" or \"9/21\".',\n",
       "    'type': 'str',\n",
       "    'default': '9/21',\n",
       "    'v': '9/21',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_captioning_from_audio_mapper': {'name': 'video_captioning_from_audio_mapper',\n",
       "  'desc': 'Mapper to caption a video according to its audio streams based on Qwen-Audio model.',\n",
       "  'enabled': True,\n",
       "  'args': {'keep_original_sample': {'name': 'keep_original_sample',\n",
       "    'desc': \"keep_original_sample (<class 'bool'>): whether to keep the original sample. If it's set to False, there will be only captioned sample in the final datasets and the original sample will be removed. It's True in default.\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_deduplicator': {'name': 'video_deduplicator',\n",
       "  'desc': 'Deduplicator to deduplicate samples at document-level using exact matching of videos between documents.',\n",
       "  'enabled': True,\n",
       "  'args': {'consider_text': {'name': 'consider_text',\n",
       "    'desc': \"consider_text (<class 'bool'>): whether to consider text hash together with video hash when applying deduplication.\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_duration_filter': {'name': 'video_duration_filter',\n",
       "  'desc': \"Keep data samples whose videos' durations are within a specified range.\",\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all videos. 'any': keep this sample if any videos meet the condition. 'all': keep this sample only if all videos meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_duration': {'name': 'max_duration',\n",
       "    'desc': \"max_duration (<class 'float'>): The max video duration to keep samples in seconds. It's sys.maxsize by default.\",\n",
       "    'type': 'float',\n",
       "    'default': 9007199254740991.0,\n",
       "    'v': 9007199254740991.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_duration': {'name': 'min_duration',\n",
       "    'desc': \"min_duration (<class 'float'>): The min video duration to keep samples in seconds. It's 0 by default.\",\n",
       "    'type': 'int',\n",
       "    'default': 0,\n",
       "    'v': 0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_extract_frames_mapper': {'name': 'video_extract_frames_mapper',\n",
       "  'desc': 'Mapper to extract frames from video files according to specified methods. Extracted Frames Data Format:     The data format for the extracted frames is a dictionary mapping     video key to extracted frames directory where the extracted     frames are saved. The dictionary follows the structure:     {         \"video_key_1\": \"/${frame_dir}/video_key_1_filename/\",         \"video_key_2\": \"/${frame_dir}/video_key_2_filename/\",         ...     }',\n",
       "  'enabled': True,\n",
       "  'args': {'duration': {'name': 'duration',\n",
       "    'desc': \"duration (<class 'float'>): The duration of each segment in seconds. If 0, frames are extracted from the entire video. If duration > 0, the video is segmented into multiple segments based on duration, and frames are extracted from each segment.\",\n",
       "    'type': 'int',\n",
       "    'default': 0,\n",
       "    'v': 0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'frame_dir': {'name': 'frame_dir',\n",
       "    'desc': \"frame_dir (<class 'str'>): Output directory to save extracted frames. If None, a default directory based on the video file path is used.\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'frame_key': {'name': 'frame_key',\n",
       "    'desc': 'frame_key (unknown): The name of field to save generated frames info.',\n",
       "    'type': 'str',\n",
       "    'default': 'video_frames',\n",
       "    'v': 'video_frames',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'frame_num': {'name': 'frame_num',\n",
       "    'desc': 'frame_num (typing.Annotated[int, Gt(gt=0)]): the number of frames to be extracted uniformly from the video. Only works when frame_sampling_method is \"uniform\". If it\\'s 1, only the middle frame will be extracted. If it\\'s 2, only the first and the last frames will be extracted. If it\\'s larger than 2, in addition to the first and the last frames, other frames will be extracted uniformly within the video duration. If \"duration\" > 0, frame_num is the number of frames per segment.',\n",
       "    'type': 'int',\n",
       "    'default': 3,\n",
       "    'v': 3,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'frame_sampling_method': {'name': 'frame_sampling_method',\n",
       "    'desc': 'frame_sampling_method (<class \\'str\\'>): sampling method of extracting frame videos from the videos. Should be one of [\"all_keyframes\", \"uniform\"]. The former one extracts all key frames (the number of which depends on the duration of the video) and the latter one extract specified number of frames uniformly from the video. If \"duration\" > 0, frame_sampling_method acts on every segment. Default: \"all_keyframes\".',\n",
       "    'type': 'str',\n",
       "    'default': 'all_keyframes',\n",
       "    'v': 'all_keyframes',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_face_blur_mapper': {'name': 'video_face_blur_mapper',\n",
       "  'desc': 'Mapper to blur faces detected in videos.',\n",
       "  'enabled': True,\n",
       "  'args': {'blur_type': {'name': 'blur_type',\n",
       "    'desc': \"blur_type (<class 'str'>): Type of blur kernel, including ['mean', 'box', 'gaussian'].\",\n",
       "    'type': 'str',\n",
       "    'default': 'gaussian',\n",
       "    'v': 'gaussian',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'cv_classifier': {'name': 'cv_classifier',\n",
       "    'desc': \"cv_classifier (<class 'str'>): OpenCV classifier path for face detection. By default, we will use 'haarcascade_frontalface_alt.xml'.\",\n",
       "    'type': 'str',\n",
       "    'default': '',\n",
       "    'v': '',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'radius': {'name': 'radius',\n",
       "    'desc': \"radius (<class 'float'>): Radius of blur kernel.\",\n",
       "    'type': 'int',\n",
       "    'default': 2,\n",
       "    'v': 2,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_frames_text_similarity_filter': {'name': 'video_frames_text_similarity_filter',\n",
       "  'desc': 'Filter to keep samples those similarities between sampled video frame images and text within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all videos. 'any': keep this sample if any videos meet the condition. 'all': keep this sample only if all videos meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'frame_num': {'name': 'frame_num',\n",
       "    'desc': 'frame_num (typing.Annotated[int, Gt(gt=0)]): the number of frames to be extracted uniformly from the video. Only works when frame_sampling_method is \"uniform\". If it\\'s 1, only the middle frame will be extracted. If it\\'s 2, only the first and the last frames will be extracted. If it\\'s larger than 2, in addition to the first and the last frames, other frames will be extracted uniformly within the video duration.',\n",
       "    'type': 'int',\n",
       "    'default': 3,\n",
       "    'v': 3,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'frame_sampling_method': {'name': 'frame_sampling_method',\n",
       "    'desc': 'frame_sampling_method (<class \\'str\\'>): sampling method of extracting frame images from the videos. Should be one of [\"all_keyframes\", \"uniform\"]. The former one extracts all key frames (the number of which depends on the duration of the video) and the latter one extract specified number of frames uniformly from the video. Default: \"all_keyframes\".',\n",
       "    'type': 'str',\n",
       "    'default': 'all_keyframes',\n",
       "    'v': 'all_keyframes',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'hf_clip': {'name': 'hf_clip',\n",
       "    'desc': \"hf_clip (unknown): clip model name on huggingface to compute the similarity between frame image and text. It's kind of language-related. For example, for Chinese datasets, ChineseCLIP might be a better choice.\",\n",
       "    'type': 'str',\n",
       "    'default': 'openai/clip-vit-base-patch32',\n",
       "    'v': 'openai/clip-vit-base-patch32',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'horizontal_flip': {'name': 'horizontal_flip',\n",
       "    'desc': \"horizontal_flip (<class 'bool'>): flip frame image horizontally (left to right).\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_score': {'name': 'max_score',\n",
       "    'desc': \"max_score (<class 'float'>): the max similarity to keep samples.\",\n",
       "    'type': 'float',\n",
       "    'default': 1.0,\n",
       "    'v': 1.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_score': {'name': 'min_score',\n",
       "    'desc': \"min_score (<class 'float'>): the min similarity to keep samples.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.1,\n",
       "    'v': 0.1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'reduce_mode': {'name': 'reduce_mode',\n",
       "    'desc': \"reduce_mode (<class 'str'>): reduce mode when one text corresponds to multiple video frame images in a chunk. 'avg': Take the average of multiple values 'max': Take the max of multiple values 'min': Take the min of multiple values\",\n",
       "    'type': 'str',\n",
       "    'default': 'avg',\n",
       "    'v': 'avg',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': 'trust_remote_code (unknown):',\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'vertical_flip': {'name': 'vertical_flip',\n",
       "    'desc': \"vertical_flip (<class 'bool'>): flip frame image vertically (top to bottom).\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_nsfw_filter': {'name': 'video_nsfw_filter',\n",
       "  'desc': 'Filter to keep samples whose videos have low nsfw scores.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all videos. 'any': keep this sample if any videos meet the condition. 'all': keep this sample only if all videos meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'frame_num': {'name': 'frame_num',\n",
       "    'desc': 'frame_num (typing.Annotated[int, Gt(gt=0)]): the number of frames to be extracted uniformly from the video. Only works when frame_sampling_method is \"uniform\". If it\\'s 1, only the middle frame will be extracted. If it\\'s 2, only the first and the last frames will be extracted. If it\\'s larger than 2, in addition to the first and the last frames, other frames will be extracted uniformly within the video duration.',\n",
       "    'type': 'int',\n",
       "    'default': 3,\n",
       "    'v': 3,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'frame_sampling_method': {'name': 'frame_sampling_method',\n",
       "    'desc': 'frame_sampling_method (<class \\'str\\'>): sampling method of extracting frame images from the videos. Should be one of [\"all_keyframes\", \"uniform\"]. The former one extracts all key frames (the number of which depends on the duration of the video) and the latter one extract specified number of frames uniformly from the video. Default: \"all_keyframes\".',\n",
       "    'type': 'str',\n",
       "    'default': 'all_keyframes',\n",
       "    'v': 'all_keyframes',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'hf_nsfw_model': {'name': 'hf_nsfw_model',\n",
       "    'desc': \"hf_nsfw_model (<class 'str'>): nsfw detection model name on huggingface.\",\n",
       "    'type': 'str',\n",
       "    'default': 'Falconsai/nsfw_image_detection',\n",
       "    'v': 'Falconsai/nsfw_image_detection',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_score': {'name': 'max_score',\n",
       "    'desc': \"max_score (<class 'float'>): the nsfw score threshold for samples. range from 0 to 1. Samples with nsfw score less than this threshold will be kept.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.5,\n",
       "    'v': 0.5,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'reduce_mode': {'name': 'reduce_mode',\n",
       "    'desc': \"reduce_mode (<class 'str'>): reduce mode for multiple sampled video frames. 'avg': Take the average of multiple values 'max': Take the max of multiple values 'min': Take the min of multiple values\",\n",
       "    'type': 'str',\n",
       "    'default': 'avg',\n",
       "    'v': 'avg',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': \"trust_remote_code (<class 'bool'>):\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_resize_aspect_ratio_mapper': {'name': 'video_resize_aspect_ratio_mapper',\n",
       "  'desc': 'Mapper to resize videos by aspect ratio. AspectRatio = W / H.',\n",
       "  'enabled': True,\n",
       "  'args': {'max_ratio': {'name': 'max_ratio',\n",
       "    'desc': 'max_ratio (<class \\'str\\'>): The maximum aspect ratio to enforce videos with an aspect ratio above `max_ratio` will be resized to match this maximum ratio. The ratio should be provided as a string in the format \"21:9\" or \"21/9\".',\n",
       "    'type': 'str',\n",
       "    'default': '21/9',\n",
       "    'v': '21/9',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_ratio': {'name': 'min_ratio',\n",
       "    'desc': 'min_ratio (<class \\'str\\'>): The minimum aspect ratio to enforce videos with an aspect ratio below `min_ratio` will be resized to match this minimum ratio. The ratio should be provided as a string in the format \"9:21\" or \"9/21\".',\n",
       "    'type': 'str',\n",
       "    'default': '9/21',\n",
       "    'v': '9/21',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'strategy': {'name': 'strategy',\n",
       "    'desc': \"strategy (<class 'str'>): The resizing strategy to apply when adjusting the video dimensions. It can be either 'decrease' to reduce the dimension or 'increase' to enlarge it. Accepted values are ['decrease', 'increase'].\",\n",
       "    'type': 'str',\n",
       "    'default': 'increase',\n",
       "    'v': 'increase',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_resize_resolution_mapper': {'name': 'video_resize_resolution_mapper',\n",
       "  'desc': 'Mapper to resize videos resolution. We leave the super resolution with deep learning for future works.',\n",
       "  'enabled': True,\n",
       "  'args': {'force_divisible_by': {'name': 'force_divisible_by',\n",
       "    'desc': 'force_divisible_by (typing.Annotated[int, Gt(gt=0)]): Ensures that both the output dimensions,             width and height, are divisible by the given integer when used             together with force_original_aspect_ratio, must be a positive             even number.',\n",
       "    'type': 'int',\n",
       "    'default': 2,\n",
       "    'v': 2,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'force_original_aspect_ratio': {'name': 'force_original_aspect_ratio',\n",
       "    'desc': \"force_original_aspect_ratio (<class 'str'>): Enable decreasing or             increasing output video width or height if necessary             to keep the original aspect ratio, including ['disable',             'decrease', 'increase'].\",\n",
       "    'type': 'str',\n",
       "    'default': 'disable',\n",
       "    'v': 'disable',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_height': {'name': 'max_height',\n",
       "    'desc': \"max_height (<class 'int'>): Videos with height more than 'max_height' will be mapped to videos with equal or smaller height.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_width': {'name': 'max_width',\n",
       "    'desc': \"max_width (<class 'int'>): Videos with width more than 'max_width' will be mapped to videos with equal of smaller width.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_height': {'name': 'min_height',\n",
       "    'desc': \"min_height (<class 'int'>): Videos with height less than 'min_height' will be mapped to videos with equal or bigger height.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_width': {'name': 'min_width',\n",
       "    'desc': \"min_width (<class 'int'>): Videos with width less than 'min_width' will be mapped to videos with equal or bigger width.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_resolution_filter': {'name': 'video_resolution_filter',\n",
       "  'desc': \"Keep data samples whose videos' resolutions are within a specified range.\",\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all videos. 'any': keep this sample if any videos meet the condition. 'all': keep this sample only if all videos meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_height': {'name': 'max_height',\n",
       "    'desc': \"max_height (<class 'int'>): The max vertical resolution.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_width': {'name': 'max_width',\n",
       "    'desc': \"max_width (<class 'int'>): The max horizontal resolution.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_height': {'name': 'min_height',\n",
       "    'desc': \"min_height (<class 'int'>): The min vertical resolution.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_width': {'name': 'min_width',\n",
       "    'desc': \"min_width (<class 'int'>): The min horizontal resolution.\",\n",
       "    'type': 'int',\n",
       "    'default': 1,\n",
       "    'v': 1,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_split_by_duration_mapper': {'name': 'video_split_by_duration_mapper',\n",
       "  'desc': 'Mapper to split video by duration.',\n",
       "  'enabled': True,\n",
       "  'args': {'keep_original_sample': {'name': 'keep_original_sample',\n",
       "    'desc': \"keep_original_sample (<class 'bool'>): whether to keep the original sample. If it's set to False, there will be only cut sample in the final datasets and the original sample will be removed. It's True in default.\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_last_split_duration': {'name': 'min_last_split_duration',\n",
       "    'desc': \"min_last_split_duration (<class 'float'>): The minimum allowable duration in seconds for the last video split. If the duration of the last split is less than this value, it will be discarded.\",\n",
       "    'type': 'int',\n",
       "    'default': 0,\n",
       "    'v': 0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'split_duration': {'name': 'split_duration',\n",
       "    'desc': \"split_duration (<class 'float'>): duration of each video split in seconds.\",\n",
       "    'type': 'int',\n",
       "    'default': 10,\n",
       "    'v': 10,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_split_by_key_frame_mapper': {'name': 'video_split_by_key_frame_mapper',\n",
       "  'desc': 'Mapper to split video by key frame.',\n",
       "  'enabled': True,\n",
       "  'args': {'keep_original_sample': {'name': 'keep_original_sample',\n",
       "    'desc': \"keep_original_sample (<class 'bool'>): whether to keep the original sample. If it's set to False, there will be only split sample in the final datasets and the original sample will be removed. It's True in default.\",\n",
       "    'type': 'bool',\n",
       "    'default': True,\n",
       "    'v': True,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_tagging_from_audio_mapper': {'name': 'video_tagging_from_audio_mapper',\n",
       "  'desc': 'Mapper to generate video tags from audio streams extracted by video using the Audio Spectrogram Transformer.',\n",
       "  'enabled': True,\n",
       "  'args': {'hf_ast': {'name': 'hf_ast',\n",
       "    'desc': \"hf_ast (<class 'str'>): path to the HF model to tag from audios.\",\n",
       "    'type': 'str',\n",
       "    'default': 'MIT/ast-finetuned-audioset-10-10-0.4593',\n",
       "    'v': 'MIT/ast-finetuned-audioset-10-10-0.4593',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'tag_field_name': {'name': 'tag_field_name',\n",
       "    'desc': 'tag_field_name (<class \\'str\\'>): the field name to store the tags. It\\'s \"video_audio_tags\" in default.',\n",
       "    'type': 'str',\n",
       "    'default': 'video_audio_tags',\n",
       "    'v': 'video_audio_tags',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': \"trust_remote_code (<class 'bool'>): whether to trust the remote code of HF models\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_tagging_from_frames_filter': {'name': 'video_tagging_from_frames_filter',\n",
       "  'desc': 'Filter to keep samples whose videos contain the given tags.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all videos. 'any': keep this sample if any videos meet the condition. 'all': keep this sample only if all videos meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'contain': {'name': 'contain',\n",
       "    'desc': \"contain (<class 'str'>): require the videos containing 'any' or 'all' tags. When tags equal to [], 'all' keeps all samples, 'any' keeps no sample.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'frame_num': {'name': 'frame_num',\n",
       "    'desc': 'frame_num (typing.Annotated[int, Gt(gt=0)]): the number of frames to be extracted uniformly from the video. Only works when frame_sampling_method is \"uniform\". If it\\'s 1, only the middle frame will be extracted. If it\\'s 2, only the first and the last frames will be extracted. If it\\'s larger than 2, in addition to the first and the last frames, other frames will be extracted uniformly within the video duration.',\n",
       "    'type': 'int',\n",
       "    'default': 3,\n",
       "    'v': 3,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'frame_sampling_method': {'name': 'frame_sampling_method',\n",
       "    'desc': 'frame_sampling_method (<class \\'str\\'>): sampling method of extracting frame images from the videos. Should be one of [\"all_keyframes\", \"uniform\"]. The former one extracts all key frames (the number of which depends on the duration of the video) and the latter one extract specified number of frames uniformly from the video. Default: \"all_keyframes\".',\n",
       "    'type': 'str',\n",
       "    'default': 'all_keyframes',\n",
       "    'v': 'all_keyframes',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'tag_field_name': {'name': 'tag_field_name',\n",
       "    'desc': 'tag_field_name (<class \\'str\\'>): the key name to store the tags in the meta field. It\\'s \"video_frame_tags\" in default.',\n",
       "    'type': 'str',\n",
       "    'default': 'video_frame_tags',\n",
       "    'v': 'video_frame_tags',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'tags': {'name': 'tags',\n",
       "    'desc': 'tags (typing.List[str]): a tag list to shift the videos, total tags can be found in https://github.com/xinyu1205/recognize-anything/blob/main/ram/data/ram_tag_list.txt # noqa: E501',\n",
       "    'type': 'list_str',\n",
       "    'default': ['people'],\n",
       "    'v': ['people'],\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_tagging_from_frames_mapper': {'name': 'video_tagging_from_frames_mapper',\n",
       "  'desc': 'Mapper to generate video tags from frames extract by video.',\n",
       "  'enabled': True,\n",
       "  'args': {'frame_num': {'name': 'frame_num',\n",
       "    'desc': 'frame_num (typing.Annotated[int, Gt(gt=0)]): the number of frames to be extracted uniformly from the video. Only works when frame_sampling_method is \"uniform\". If it\\'s 1, only the middle frame will be extracted. If it\\'s 2, only the first and the last frames will be extracted. If it\\'s larger than 2, in addition to the first and the last frames, other frames will be extracted uniformly within the video duration.',\n",
       "    'type': 'int',\n",
       "    'default': 3,\n",
       "    'v': 3,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'frame_sampling_method': {'name': 'frame_sampling_method',\n",
       "    'desc': 'frame_sampling_method (<class \\'str\\'>): sampling method of extracting frame images from the videos. Should be one of [\"all_keyframes\", \"uniform\"]. The former one extracts all key frames (the number of which depends on the duration of the video) and the latter one extract specified number of frames uniformly from the video. Default: \"all_keyframes\".',\n",
       "    'type': 'str',\n",
       "    'default': 'all_keyframes',\n",
       "    'v': 'all_keyframes',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'tag_field_name': {'name': 'tag_field_name',\n",
       "    'desc': 'tag_field_name (<class \\'str\\'>): the field name to store the tags. It\\'s \"video_frame_tags\" in default.',\n",
       "    'type': 'str',\n",
       "    'default': 'video_frame_tags',\n",
       "    'v': 'video_frame_tags',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'video_watermark_filter': {'name': 'video_watermark_filter',\n",
       "  'desc': 'Filter to keep samples whose videos have no watermark with high probability.',\n",
       "  'enabled': True,\n",
       "  'args': {'any_or_all': {'name': 'any_or_all',\n",
       "    'desc': \"any_or_all (<class 'str'>): keep this sample with 'any' or 'all' strategy of all videos. 'any': keep this sample if any videos meet the condition. 'all': keep this sample only if all videos meet the condition.\",\n",
       "    'type': 'str',\n",
       "    'default': 'any',\n",
       "    'v': 'any',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'frame_num': {'name': 'frame_num',\n",
       "    'desc': 'frame_num (typing.Annotated[int, Gt(gt=0)]): the number of frames to be extracted uniformly from the video. Only works when frame_sampling_method is \"uniform\". If it\\'s 1, only the middle frame will be extracted. If it\\'s 2, only the first and the last frames will be extracted. If it\\'s larger than 2, in addition to the first and the last frames, other frames will be extracted uniformly within the video duration.',\n",
       "    'type': 'int',\n",
       "    'default': 3,\n",
       "    'v': 3,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'frame_sampling_method': {'name': 'frame_sampling_method',\n",
       "    'desc': 'frame_sampling_method (<class \\'str\\'>): sampling method of extracting frame images from the videos. Should be one of [\"all_keyframes\", \"uniform\"]. The former one extracts all key frames (the number of which depends on the duration of the video) and the latter one extract specified number of frames uniformly from the video. Default: \"all_keyframes\".',\n",
       "    'type': 'str',\n",
       "    'default': 'all_keyframes',\n",
       "    'v': 'all_keyframes',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'hf_watermark_model': {'name': 'hf_watermark_model',\n",
       "    'desc': \"hf_watermark_model (<class 'str'>): watermark detection model name on huggingface.\",\n",
       "    'type': 'str',\n",
       "    'default': 'amrul-hzz/watermark_detector',\n",
       "    'v': 'amrul-hzz/watermark_detector',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'prob_threshold': {'name': 'prob_threshold',\n",
       "    'desc': \"prob_threshold (<class 'float'>): the predicted watermark probability threshold for samples. range from 0 to 1. Samples with watermark probability less than this threshold will be kept.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.8,\n",
       "    'v': 0.8,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'reduce_mode': {'name': 'reduce_mode',\n",
       "    'desc': \"reduce_mode (<class 'str'>): reduce mode for multiple sampled video frames. 'avg': Take the average of multiple values 'max': Take the max of multiple values 'min': Take the min of multiple values\",\n",
       "    'type': 'str',\n",
       "    'default': 'avg',\n",
       "    'v': 'avg',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'trust_remote_code': {'name': 'trust_remote_code',\n",
       "    'desc': \"trust_remote_code (<class 'bool'>):\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'whitespace_normalization_mapper': {'name': 'whitespace_normalization_mapper',\n",
       "  'desc': \"Mapper to normalize different kinds of whitespaces to whitespace ' ' (0x20) in text samples.  Different kinds of whitespaces can be found here: https://en.wikipedia.org/wiki/Whitespace_character\",\n",
       "  'enabled': True,\n",
       "  'args': {},\n",
       "  'stats': {}},\n",
       " 'word_repetition_filter': {'name': 'word_repetition_filter',\n",
       "  'desc': 'Filter to keep samples with word-level n-gram repetition ratio within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'lang': {'name': 'lang',\n",
       "    'desc': \"lang (<class 'str'>): sample in which language.\",\n",
       "    'type': 'str',\n",
       "    'default': 'en',\n",
       "    'v': 'en',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_ratio': {'name': 'max_ratio',\n",
       "    'desc': \"max_ratio (<class 'float'>): The max filter ratio in this op, samples will be filtered if their word-level n-gram repetition ratio exceeds this parameter.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.5,\n",
       "    'v': 0.5,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_ratio': {'name': 'min_ratio',\n",
       "    'desc': \"min_ratio (<class 'float'>): The min filter ratio in this op, samples will be filtered if their word-level n-gram repetition ratio is below this parameter.\",\n",
       "    'type': 'float',\n",
       "    'default': 0.0,\n",
       "    'v': 0.0,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'rep_len': {'name': 'rep_len',\n",
       "    'desc': 'rep_len (typing.Annotated[int, Gt(gt=0)]): Repetition length for word-level n-gram.',\n",
       "    'type': 'int',\n",
       "    'default': 10,\n",
       "    'v': 10,\n",
       "    'options': None,\n",
       "    'min': 0,\n",
       "    'max': None},\n",
       "   'tokenization': {'name': 'tokenization',\n",
       "    'desc': \"tokenization (<class 'bool'>): whether to use model to tokenize documents\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}},\n",
       " 'words_num_filter': {'name': 'words_num_filter',\n",
       "  'desc': 'Filter to keep samples with total words number within a specific range.',\n",
       "  'enabled': True,\n",
       "  'args': {'lang': {'name': 'lang',\n",
       "    'desc': \"lang (<class 'str'>): sample in which language.\",\n",
       "    'type': 'str',\n",
       "    'default': 'en',\n",
       "    'v': 'en',\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'max_num': {'name': 'max_num',\n",
       "    'desc': \"max_num (<class 'int'>): The max filter word number in this op, samples will be filtered if their word number exceeds this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 9007199254740991,\n",
       "    'v': 9007199254740991,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'min_num': {'name': 'min_num',\n",
       "    'desc': \"min_num (<class 'int'>): The min filter word number in this op, samples will be filtered if their word number is below this parameter.\",\n",
       "    'type': 'int',\n",
       "    'default': 10,\n",
       "    'v': 10,\n",
       "    'options': None,\n",
       "    'min': None,\n",
       "    'max': None},\n",
       "   'tokenization': {'name': 'tokenization',\n",
       "    'desc': \"tokenization (<class 'bool'>): whether to use model to tokenize documents\",\n",
       "    'type': 'bool',\n",
       "    'default': False,\n",
       "    'v': False,\n",
       "    'options': [True, False],\n",
       "    'min': None,\n",
       "    'max': None}},\n",
       "  'stats': {}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state, used for llm query, save, and load\n",
    "op_pool.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db887b19c08a9b64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T07:01:24.254749Z",
     "start_time": "2025-06-18T07:01:24.251754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./configs/demo-recipe.yaml'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export recipe\n",
    "op_pool.export_config(\n",
    "    project_name=\"demo\",\n",
    "    dataset_path=\"./data/demo-dataset.jsonl\",\n",
    "    nproc=4,\n",
    "    export_path=\"./outputs/processed_data.jsonl\",\n",
    "    config_path=\"./configs/demo-recipe.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bfb55741b8931c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T07:01:24.279674Z",
     "start_time": "2025-06-18T07:01:24.271399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# enable/disable an operator\n",
    "print(op_pool[\"alphanumeric_filter\"].enabled)\n",
    "op_pool.act(op_name=\"alphanumeric_filter\", action_type=\"disable\")\n",
    "print(op_pool[\"alphanumeric_filter\"].enabled)\n",
    "op_pool.act(op_name=\"alphanumeric_filter\", action_type=\"enable\")\n",
    "print(op_pool[\"alphanumeric_filter\"].enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e596f0d411ae14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T07:01:24.295554Z",
     "start_time": "2025-06-18T07:01:24.290428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set arg value\n",
    "op_pool.act(op_name=\"alphanumeric_filter\", action_type=\"set_arg\",\n",
    "            arg_name=\"min_ratio\", v=0.2)\n",
    "op_pool[\"alphanumeric_filter\"].args[\"min_ratio\"].v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80247993f7556f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T07:01:24.313267Z",
     "start_time": "2025-06-18T07:01:24.307168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = dict(mean=0.3, std=0.04, min=0.12, max=0.89, quantiles=[0.01 * i for i in range(101)])\n",
    "op_pool[\"alphanumeric_filter\"].update_with_stats(stats)\n",
    "# set arg value as the p% quantile\n",
    "op_pool.act(op_name=\"alphanumeric_filter\", action_type=\"set_arg\",\n",
    "            arg_name=\"min_ratio\", p=30) # p=0.3 is also acceptable\n",
    "op_pool[\"alphanumeric_filter\"].args[\"min_ratio\"].v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1b3d080157322be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T07:01:24.328854Z",
     "start_time": "2025-06-18T07:01:24.319588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18, 0.42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set filter args as mean \\pm k * std\n",
    "op_pool.act(op_name=\"alphanumeric_filter\", action_type=\"set_arg\",\n",
    "            k=3)\n",
    "op_pool[\"alphanumeric_filter\"].args[\"min_ratio\"].v, op_pool[\"alphanumeric_filter\"].args[\"max_ratio\"].v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
